{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "325bf22c-dab4-42e7-9596-ca9c2201d560",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <script type=\"application/javascript\" id=\"jupyter_black\">\n",
       "                (function() {\n",
       "                    if (window.IPython === undefined) {\n",
       "                        return\n",
       "                    }\n",
       "                    var msg = \"WARNING: it looks like you might have loaded \" +\n",
       "                        \"jupyter_black in a non-lab notebook with \" +\n",
       "                        \"`is_lab=True`. Please double check, and if \" +\n",
       "                        \"loading with `%load_ext` please review the README!\"\n",
       "                    console.log(msg)\n",
       "                    alert(msg)\n",
       "                })()\n",
       "                </script>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa509e9-5226-4967-a80f-7a5f01bba028",
   "metadata": {},
   "source": [
    "# Set-up OpenAI API key\n",
    "\n",
    "https://platform.openai.com/account/api-keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a0e4ae2-5d10-464f-a8c7-8da99d48285f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "with open(\"../API_KEY\", \"r\") as f:\n",
    "    key = f.read()\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d36a5-d2f2-4682-ab2c-c3a31c8f38b8",
   "metadata": {},
   "source": [
    "# General Plan:\n",
    "- Basic example of new `function_call`\n",
    "- Converting existing functions for use with `function_call`\n",
    "- Give GPT the ability to make new functions\n",
    "- Allow GPT to use it's own newly created functions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3daa420-25c9-4739-8aa1-d31c38c34517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Main imports\n",
    "import openai\n",
    "import json  # Converting between string and dict\n",
    "\n",
    "# Other imports that will be explained as they come up\n",
    "import os\n",
    "import inspect\n",
    "import importlib.util\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1ef92-60b9-43b8-af8f-e9711c1762b2",
   "metadata": {},
   "source": [
    "# Basic Example of `function_call`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7858760-4d6c-47b3-8de3-11128fe9b243",
   "metadata": {},
   "source": [
    "## Example function for GPT to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb27a074-def7-4fcf-8b25-a2fd3b205e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sports_headlines(\n",
    "    sport: str, team_names: list[str] = None, num_results: int = 3\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Gets the latest headlines for the given sport. Optionally filtering by specific team names\n",
    "\n",
    "    Args:\n",
    "        sport: Which sport to search within. Can be 'soccer', 'basketball', or 'baseball'.\n",
    "        team_names: Optionally provide specific team names to search for\n",
    "        num_results: How many headlines to return\n",
    "    \"\"\"\n",
    "    # Here you would implement searching through a database or calls to a search API etc\n",
    "    # We'll just use some fictional results I pre-prepared\n",
    "    with open(\"fictional_headlines.json\", \"r\") as f:\n",
    "        all_headlines = json.load(f)\n",
    "    headlines = all_headlines.get(sport, None)\n",
    "    if not headlines:\n",
    "        return \"No headlines found\"\n",
    "    if team_names:\n",
    "        headlines = [\n",
    "            headline\n",
    "            for headline in headlines\n",
    "            if any([team in headline for team in team_names])\n",
    "        ]\n",
    "    return headlines[:num_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0164fadb-9d41-4708-b668-10d6fb6874d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GET_SPORTS_HEADLINES_DESCRIPTION = {\n",
    "    \"name\": \"get_sports_headlines\",\n",
    "    \"description\": \"Gets the latest headlines for the given sport. Optionally filtering by specific team names\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"sport\": {\n",
    "                \"type\": \"string\",\n",
    "                \"enum\": [\"soccer\", \"basketball\", \"baseball\"],\n",
    "                \"description\": \"Which sport to search within\",\n",
    "            },\n",
    "            \"team_names\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"},\n",
    "                \"description\": \"Optionally provide specific team names to search for\",\n",
    "            },\n",
    "            \"num_results\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"How many headlines to return\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"sport\"],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41eb1d-b864-46f2-abb8-17c8fe8291e5",
   "metadata": {},
   "source": [
    "## Call to openai with new completion parameters\n",
    "`functions` and `function_call`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2684adb2-52c6-45e8-9fd6-5eaa58d22989",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the latest headlines for Manchester and Aresnal, can you tell me whether the teams won or lost for each headline?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_message = \"Based on the latest headlines for Manchester and Aresnal, can you tell me whether the teams won or lost for each headline?\"\n",
    "user_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52c08247-7681-4b03-9061-4fb1401202db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sorry, as an AI language model, I don't have access to the latest headlines or live update sports scores. Please browse the internet or news outlets to get the latest information on Manchester and Arsenal Football Club's performance and scores.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what we get back without using functions first\n",
    "baseline_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0301\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    ")\n",
    "baseline_response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919b13b-6adb-4972-9e1d-d1d2071ee8f0",
   "metadata": {},
   "source": [
    "---\n",
    "As expected, not a very satisfying response\n",
    "\n",
    "Now let's use the new model with the new API parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12de0f15-b64c-4ac6-9573-5fbe005c531a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7Sw2W4Vck8ptS8p6YZWQ7SbOnOLfG at 0x19e75bb2c90> JSON: {\n",
       "  \"id\": \"chatcmpl-7Sw2W4Vck8ptS8p6YZWQ7SbOnOLfG\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1687130644,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": null,\n",
       "        \"function_call\": {\n",
       "          \"name\": \"get_sports_headlines\",\n",
       "          \"arguments\": \"{\\n  \\\"sport\\\": \\\"soccer\\\",\\n  \\\"team_names\\\": [\\\"Manchester\\\", \\\"Arsenal\\\"],\\n  \\\"num_results\\\": 5\\n}\"\n",
       "        }\n",
       "      },\n",
       "      \"finish_reason\": \"function_call\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 130,\n",
       "    \"completion_tokens\": 39,\n",
       "    \"total_tokens\": 169\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[{\"role\": \"user\", \"content\": user_message}],\n",
    "    functions=[\n",
    "        GET_SPORTS_HEADLINES_DESCRIPTION,\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "first_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb7fb77-9f90-4d53-980b-b274badfbbda",
   "metadata": {},
   "source": [
    "---\n",
    "We can see that GPT decided to make a `function_call` (rather than returning `content` like it would have before the `0613` update)\n",
    "\n",
    "It even realised that we are probably talking about 'soccer' if we are asking about 'Manchester' and 'Arsenal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bf4211-3631-4a0e-8408-a8a9b5ae89b6",
   "metadata": {},
   "source": [
    "## Get the response from the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8be6434e-2f88-4f01-8894-2793eace7412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function output:\n",
      "['Manchester United Stuns Rivals: Late Goal Seals Victory in High-Stakes Match Against Liverpool', \"Manchester United Triumphs: Bruno Fernandes' Hat Trick Silences Critics in Decisive Win over Chelsea\", 'Arsenal Secures Victory: Pierre-Emerick Aubameyang Shines in Nail-biting Finish Against Tottenham', 'Manchester City Stunned: Late Own Goal Gives Aston Villa Shock Win', 'The Manchester Derby Ends in Stalemate: Defensive Masterclass from Both United and City']\n"
     ]
    }
   ],
   "source": [
    "# Extract the returned message\n",
    "function_call_message = first_response[\"choices\"][0][\"message\"]\n",
    "\n",
    "# From that message, get the name of the function called\n",
    "function_name = function_call_message[\"function_call\"][\"name\"]\n",
    "\n",
    "# Also get the arguments (this is a string representation of a JSON dict of arguments)\n",
    "arguments = function_call_message[\"function_call\"].get(\"arguments\")\n",
    "# Convert from string to dict\n",
    "arguments = json.loads(arguments)\n",
    "\n",
    "# Make the call to the function with the arguments that the LLM decided\n",
    "function_response = get_sports_headlines(\n",
    "    sport=arguments[\"sport\"],\n",
    "    team_names=arguments.get(\"team_names\", None),\n",
    "    num_results=arguments.get(\"num_results\", 5),\n",
    ")\n",
    "# function_response = get_weather_report(\n",
    "#     **arguments,  # Unpack the arguments as keyword: value pairs\n",
    "# )\n",
    "\n",
    "# Look at what the function returned\n",
    "print(f\"Function output:\\n{function_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cea2e-ddfa-43af-a45f-da1a5c04727c",
   "metadata": {},
   "source": [
    "## Convert response into message that GPT understands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a97d0f5-0749-43ca-bee4-f644aafebfa1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'function',\n",
       " 'name': 'get_sports_headlines',\n",
       " 'content': '[\\'Manchester United Stuns Rivals: Late Goal Seals Victory in High-Stakes Match Against Liverpool\\', \"Manchester United Triumphs: Bruno Fernandes\\' Hat Trick Silences Critics in Decisive Win over Chelsea\", \\'Arsenal Secures Victory: Pierre-Emerick Aubameyang Shines in Nail-biting Finish Against Tottenham\\', \\'Manchester City Stunned: Late Own Goal Gives Aston Villa Shock Win\\', \\'The Manchester Derby Ends in Stalemate: Defensive Masterclass from Both United and City\\']'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response_message = {\n",
    "    \"role\": \"function\",\n",
    "    \"name\": function_name,\n",
    "    \"content\": str(function_response),  # content must always be a string\n",
    "}\n",
    "function_response_message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40976993-b1d5-47ac-862f-2585814e685c",
   "metadata": {},
   "source": [
    "## Call to openai including the extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "783424a0-5901-40fa-9a92-c891dec97986",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7Sw2XpbFY0WpbWwCwUhUKlZ1bdiPJ at 0x19e75bb2f30> JSON: {\n",
       "  \"id\": \"chatcmpl-7Sw2XpbFY0WpbWwCwUhUKlZ1bdiPJ\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1687130645,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Based on the latest headlines:\\n\\n1. Manchester United Stuns Rivals: Late Goal Seals Victory in High-Stakes Match Against Liverpool - Manchester United won.\\n2. Manchester United Triumphs: Bruno Fernandes' Hat Trick Silences Critics in Decisive Win over Chelsea - Manchester United won.\\n3. Arsenal Secures Victory: Pierre-Emerick Aubameyang Shines in Nail-biting Finish Against Tottenham - Arsenal won.\\n4. Manchester City Stunned: Late Own Goal Gives Aston Villa Shock Win - Manchester City lost.\\n5. The Manchester Derby Ends in Stalemate: Defensive Masterclass from Both United and City - The match ended in a draw.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 282,\n",
       "    \"completion_tokens\": 135,\n",
       "    \"total_tokens\": 417\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_message},\n",
    "        # Add the context of the previous function call and response\n",
    "        function_call_message,\n",
    "        function_response_message,\n",
    "    ],\n",
    "    # Leaving these here just to demonstrate that GPT only uses functions when necessary\n",
    "    functions=[\n",
    "        GET_SPORTS_HEADLINES_DESCRIPTION,\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "181c93cb-a565-4a0b-8f69-6a157783549a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the latest headlines:\n",
      "\n",
      "1. Manchester United Stuns Rivals: Late Goal Seals Victory in High-Stakes Match Against Liverpool - Manchester United won.\n",
      "2. Manchester United Triumphs: Bruno Fernandes' Hat Trick Silences Critics in Decisive Win over Chelsea - Manchester United won.\n",
      "3. Arsenal Secures Victory: Pierre-Emerick Aubameyang Shines in Nail-biting Finish Against Tottenham - Arsenal won.\n",
      "4. Manchester City Stunned: Late Own Goal Gives Aston Villa Shock Win - Manchester City lost.\n",
      "5. The Manchester Derby Ends in Stalemate: Defensive Masterclass from Both United and City - The match ended in a draw.\n"
     ]
    }
   ],
   "source": [
    "print(second_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74558f70-d566-4154-92aa-c810843b4b55",
   "metadata": {},
   "source": [
    "---\n",
    "Now GPT gives us a nice summary of that information, including an inferred win/loss based on the headline!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2200f-10d1-45f2-b612-d5ce841d3ce7",
   "metadata": {},
   "source": [
    "# Automate making the JSON description of functions for use with GPT\n",
    "\n",
    "It's a bit tedious to write the JSON description of your functions, so let's automate that.\n",
    "\n",
    "We'll get GPT to do the conversion for us. It won't be 100% reliable, but it will handle a wide variety of existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65456ade-12d7-4bae-aa3b-283c29ed4bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspect.getsource(get_weather_report):\n",
      " def get_sports_headlines(\n",
      "    sport: str, team_names: list[str] = None, num_results: int = 3\n",
      ") -> list[str]:\n",
      "    \"\"\"\n",
      "    Gets the latest headlines for the given sport. Optionally filtering by specific team names\n",
      "\n",
      "    Args:\n",
      "        sport: Which sport to search within. Can be 'soccer', 'basketball', or 'baseball'.\n",
      "        team_names: Optionally provide specific team names to search for\n",
      "        num_results: How many headlines to return\n",
      "    \"\"\"\n",
      "    # Here you would implement searching through a database or calls to a search API etc\n",
      "    # We'll just use some fictional results I pre-prepared\n",
      "    with open(\"fictional_headlines.json\", \"r\") as f:\n",
      "        all_headlines = json.load(f)\n",
      "    headlines = all_headlines.get(sport, None)\n",
      "    if not headlines:\n",
      "        return \"No headlines found\"\n",
      "    if team_names:\n",
      "        headlines = [\n",
      "            headline\n",
      "            for headline in headlines\n",
      "            if any([team in headline for team in team_names])\n",
      "        ]\n",
      "    return headlines[:num_results]\n",
      "\n",
      "---------------------\n",
      "\n",
      "Check functions are of type `Callable`:\n",
      " True\n"
     ]
    }
   ],
   "source": [
    "# Quickly demonstrate the use of these imports for those that aren't familiar\n",
    "import inspect\n",
    "from typing import Callable\n",
    "\n",
    "print(\n",
    "    \"Inspect.getsource(get_weather_report):\\n\", inspect.getsource(get_sports_headlines)\n",
    ")\n",
    "print(\"---------------------\")\n",
    "print(\n",
    "    \"\\nCheck functions are of type `Callable`:\\n\",\n",
    "    isinstance(get_sports_headlines, Callable),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9ad98d-7e8d-4f05-9bf5-9e7dd6335a18",
   "metadata": {},
   "source": [
    "## Build the system prompt\n",
    "\n",
    "This will help guide GPT to do what we want it to do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b371f307-cc23-493d-be51-e7a501821f0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_JSON_REP = '''Your job is to convert a python function into a json representation with a specific form.\n",
    "For example, given this function:\n",
    "```\n",
    "def get_weather_report(day_of_week: int, weather_type: str, temperature: float = 10.0) -> str:\n",
    "    \"\"\"\n",
    "    Converts information about weather into a string representation.\n",
    "\n",
    "    Args:\n",
    "        day_of_week (int): The day of the week from 0 to 6.\n",
    "        weather_type (str): The type of weather, can be \"sunny\", \"rainy\", or \"windy\".\n",
    "        temperature (float, optional): Temperature in Celsius. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the weather report.\n",
    "    \"\"\"\n",
    "    return f'For the {day_of_week}th day of the week, the weather is predicted to be {weather_type} with a max temperature of {temperature}'\n",
    "```\n",
    "\n",
    "You should return:\n",
    "```\n",
    "{\n",
    "    \"name\": \"get_weather_report\",\n",
    "    \"description\": \"Converts information about weather into a string representation\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"day_of_week\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The day of the week from 0 to 6\",\n",
    "            },\n",
    "            \"weather_type\": {\"type\": \"string\", \"enum\": [\"sunny\", \"rainy\", \"windy\"]},\n",
    "            \"temperature\": {\"type\": \"number\", \"description\": \"Temperature in Celsius. Defaults to 10.0.\"},\n",
    "        },\n",
    "        \"required\": [\"day_of_week\", \"weather_type\"],\n",
    "    },\n",
    "}\n",
    "```\n",
    "Return the JSON ONLY.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b7d429c-2979-4e41-8b4b-309afb351cf5",
   "metadata": {},
   "source": [
    "## Make the function\n",
    "\n",
    "Make it easy to get the JSON representation directly from an existing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "581f40e5-217b-49c2-abe3-a56363264884",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_json_representation(func: Callable) -> dict:\n",
    "    \"\"\"\n",
    "    Uses the openai.ChatCompletion.create endpoint to return the JSON representation of a function (for GPT to use)\n",
    "\n",
    "    Args:\n",
    "        function_str (str): The function to generate a JSON representation for\n",
    "\n",
    "    Returns:\n",
    "        dict: The JSON representation of func\n",
    "    \"\"\"\n",
    "    # Get the code of the given func\n",
    "    function_code = inspect.getsource(func)\n",
    "\n",
    "    # Ask OpenAI to make the conversion to JSON format\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        temperature=0.0,  # Deterministic output (most probable next word every time)\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_JSON_REP},\n",
    "            {\"role\": \"user\", \"content\": function_code},  # Then give the func code\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    assistant_response = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # convert to dict (JSON)\n",
    "    description_json = json.loads(assistant_response)\n",
    "    return description_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ab0bd1f-a2b1-4303-bdb9-8e7c25a4b54e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_sports_headlines',\n",
       " 'description': 'Gets the latest headlines for the given sport. Optionally filtering by specific team names',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'sport': {'type': 'string',\n",
       "    'enum': ['soccer', 'basketball', 'baseball']},\n",
       "   'team_names': {'type': 'array',\n",
       "    'items': {'type': 'string'},\n",
       "    'description': 'Optionally provide specific team names to search for'},\n",
       "   'num_results': {'type': 'number',\n",
       "    'description': 'How many headlines to return'}},\n",
       "  'required': ['sport']},\n",
       " 'returns': {'type': 'array', 'items': {'type': 'string'}}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_json_representation(get_sports_headlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a02c45-fc35-4942-ba37-c7d13a967a12",
   "metadata": {},
   "source": [
    "---\n",
    "That's pretty good. GPT added a `returns` field here that we didn't ask for, but that's OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bde733-51af-487b-a84b-e13631871c69",
   "metadata": {},
   "source": [
    "# Get GPT to make new functions\n",
    "\n",
    "Let's guide GPT on how to make functions for itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0110588-10f4-41c6-88a3-1f17275482c6",
   "metadata": {},
   "source": [
    "## Create some necessary helper functions\n",
    "\n",
    "To actually get a useable function from the string GPT will return to us, we'll save the text to a `.py` file, then load it using `importlib`\n",
    "\n",
    "These are the functions required to do that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9939ed5c-af23-466b-9dd9-dfc86952e24e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib.util\n",
    "\n",
    "FUNCTIONS_FOLDER = \"functions\"\n",
    "os.makedirs(FUNCTIONS_FOLDER, exist_ok=True)\n",
    "\n",
    "\n",
    "def sanitize_python_code(code: str) -> str:\n",
    "    \"\"\"If the code is surrounded by markdown triple backticks, they are removed.\"\"\"\n",
    "    lines = code.split(\"\\n\")\n",
    "    filtered_lines = [line for line in lines if not line.startswith(\"```\")]\n",
    "    filtered_code = \"\\n\".join(filtered_lines)\n",
    "    return filtered_code\n",
    "\n",
    "\n",
    "def filepath(folder: str, function_name: str) -> str:\n",
    "    return os.path.join(folder, f\"{function_name}.py\")\n",
    "\n",
    "\n",
    "def write_to_py_file(folder: str, function_name: str, file_contents: str):\n",
    "    \"\"\"Write code to .py file\"\"\"\n",
    "    # Save function to .py file\n",
    "    file_contents = sanitize_python_code(file_contents)\n",
    "    with open(filepath(folder, function_name), \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "\n",
    "\n",
    "def load_function_from_file(folder: str, function_name: str) -> Callable:\n",
    "    \"\"\"\n",
    "    Loads a function from a .py file.\n",
    "    \"\"\"\n",
    "    # Load the spec of the module\n",
    "    spec = importlib.util.spec_from_file_location(\n",
    "        \"temporary\", filepath(folder, function_name)\n",
    "    )\n",
    "\n",
    "    # Create a module from the spec\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "\n",
    "    # Execute the module to get the function\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    # Get the function from the module\n",
    "    function = getattr(module, function_name)\n",
    "\n",
    "    return function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d8c696-693d-4b38-a2fd-06462bdefbf0",
   "metadata": {},
   "source": [
    "## Build the system prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "38bef653-de1f-49aa-b457-0890a4b13a3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_MAKE_NEW_FUNCTION = \"\"\"You are an expert python coder that will be tasked with generating the code to go in a .py file for a single function given some specific information from the user.\n",
    "You will be provided:\n",
    "    - function_name: The name to give the new function\n",
    "    - arg_descriptions: Descriptions of all the arguments the function should take (if their types are missing, try to infer them)\n",
    "    - description: What the function should do with the given arguments\n",
    "\n",
    "When generating the new function you should follow these rules:\n",
    "    - Include ONLY the text that will be in the python file (e.g. starting with `import ...` unless no imports are necessary in which case, starting with `def ...`)\n",
    "    - Do NOT include any plain text explanation at the end of the written code\n",
    "    - Use the latest python programming techniques and best practices\n",
    "    - Use the latest/best python libraries when appropriate (e.g. if plotting, use `plotly` instead of `matplotlib` because plotly is better library even though matplotlib is better known)\n",
    "    - Always include a google style docstring\n",
    "    - Include type hints for the inputs and output\n",
    "    - Include all necessary imports (including `typing` ones e.g. List)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bee4ac7-fc76-48c3-98ea-1bb03d2443a9",
   "metadata": {},
   "source": [
    "## Make the `make_new_function` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0d9c161-501b-4e0a-83bc-d15a271d82b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_new_function(\n",
    "    function_name: str, arg_descriptions: str, description: str\n",
    ") -> Callable:\n",
    "    \"\"\"\n",
    "    Use this if an existing function doesn't exist, and it would be helpful to have a new function to complete a task.\n",
    "    The new function will be made to carry out the task described in the `description` given the arguments described by `arg_descriptions`\n",
    "\n",
    "    Args:\n",
    "        function_name: Name to give the new function (should follow python naming conventions)\n",
    "        arg_descriptions: A description of any arguments that the function should take (including type, and default value if appropriate)\n",
    "        description: A description of what the function should do (including the what it should output)\n",
    "    \"\"\"\n",
    "\n",
    "    # Format the message we'll send to GPT in the form we have described in the system prompt\n",
    "    formatted_input = f\"function_name: {function_name}\\narg_descriptions: {arg_descriptions}\\ndescription: {description}\"\n",
    "\n",
    "    # Ask OpenAI to make the new function\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_MAKE_NEW_FUNCTION},\n",
    "            {\"role\": \"user\", \"content\": formatted_input},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    function_code = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "    # Tidy it, and convert to an actual function\n",
    "    function_code = sanitize_python_code(function_code)\n",
    "    write_to_py_file(FUNCTIONS_FOLDER, function_name, function_code)\n",
    "    func = load_function_from_file(FUNCTIONS_FOLDER, function_name)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0975eede-b759-428e-aec0-6bac080a3780",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def add_numbers(numbers: List[float]) -> float:\n",
      "    \"\"\"\n",
      "    Adds up the list of numbers.\n",
      "\n",
      "    Args:\n",
      "        numbers: A list of numbers to add up.\n",
      "\n",
      "    Returns:\n",
      "        The sum of the numbers.\n",
      "    \"\"\"\n",
      "    return sum(numbers)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func = make_new_function(\n",
    "    function_name=\"add_numbers\",\n",
    "    arg_descriptions=\"numbers: a list of numbers to add up\",\n",
    "    description=\"Adds up the list of numbers\",\n",
    ")\n",
    "print(inspect.getsource(func))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f398ae2-6b85-4ec9-8e7f-9069e4aacf6e",
   "metadata": {},
   "source": [
    "# Integrate the ability to generate new functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ef6b6d-cb48-4ff7-9503-88f78007202f",
   "metadata": {},
   "source": [
    "## Build a systemp prompt\n",
    "We'll make a fairly general system prompt but emphasise that in general it would be good to use functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "895b64b6-4dc2-4cf4-a06d-b33acc3e3a5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_GENERAL = \"\"\"You are a helpful AI assistant. \n",
    "When responding you should follow these rules:\n",
    " - You should always use functions as an intermediate step to respond to the user when appropriate (e.g. when being asked to do math, use a function to do the calculation)\n",
    " - You should ONLY consider using the functions provided (e.g. do not assume you can use `python`, that does NOT exist)\n",
    " - If there is a missing function that would be useful, make a call to `make_new_function` to create it BEFORE responding to the user\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb17156-61c8-44ed-8511-d20e4a3bdadb",
   "metadata": {},
   "source": [
    "GPT-3.5 has a bit of a problem of hallucinating functions that don't exist (e.g. It often assumes it has a `python` function if you let it decide what to do automatically)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832804ad-5149-4289-ae6c-23494c8a7be0",
   "metadata": {},
   "source": [
    "## Add the `make_new_function` function to a collection of we'll give to GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b603b432-cbd9-44ca-adfe-21a21ca351bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'make_new_function',\n",
       "  'description': \"Use this if an existing function doesn't exist, and it would be helpful to have a new function to complete a task. The new function will be made to carry out the task described in the `description` given the arguments described by `arg_descriptions`\",\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'function_name': {'type': 'string'},\n",
       "    'arg_descriptions': {'type': 'string'},\n",
       "    'description': {'type': 'string'}},\n",
       "   'required': ['function_name', 'arg_descriptions', 'description']},\n",
       "  'returns': {'type': 'callable'}}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize a dictionary that will collect the functions we'll let GPT use\n",
    "available_functions = {\n",
    "    \"make_new_function\": {\n",
    "        \"func\": make_new_function,\n",
    "        \"description\": get_json_representation(make_new_function),\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def to_descriptions_list(functions_dict: dict) -> list[dict]:\n",
    "    \"\"\"List out the 'description' part of the available functions dict for GPT to use\"\"\"\n",
    "    return [entry[\"description\"] for entry in functions_dict.values()]\n",
    "\n",
    "\n",
    "# This is what we'll pass to GPT\n",
    "to_descriptions_list(available_functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ccf16-21ae-4f23-a8bb-c2d85f9569bd",
   "metadata": {},
   "source": [
    "---\n",
    "So we are starting out with only one function that will be made available to GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4a5e0-aa58-4132-9b5d-13ea1a05fca1",
   "metadata": {},
   "source": [
    "## Make an example user request\n",
    "\n",
    "We'll ask for something that GPT is bad at doing by itself (like basic math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e72754e0-1abe-4cbb-9078-1a7dc2de661b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_request = \"What is the result of multiplying together all of these numbers [3,2,6,3,6,5,4,3,6]?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed447b67-38a6-40e5-a1a4-8ae7a352389c",
   "metadata": {},
   "source": [
    "## Request an initial response\n",
    "Now we'll see what GPT wants to do with the users request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "480b3ce8-98a5-405c-8727-0ab9a87a3e53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"index\": 0,\n",
      "  \"message\": {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": null,\n",
      "    \"function_call\": {\n",
      "      \"name\": \"make_new_function\",\n",
      "      \"arguments\": \"{\\n  \\\"function_name\\\": \\\"multiply_numbers\\\",\\n  \\\"arg_descriptions\\\": \\\"numbers: number[]\\\",\\n  \\\"description\\\": \\\"Multiplies together all the numbers in the given array.\\\"\\n}\"\n",
      "    }\n",
      "  },\n",
      "  \"finish_reason\": \"function_call\"\n",
      "}\n",
      "---------------\n",
      "Requested Function:\n",
      " {\n",
      "  \"function_name\": \"multiply_numbers\",\n",
      "  \"arg_descriptions\": \"numbers: number[]\",\n",
      "  \"description\": \"Multiplies together all the numbers in the given array.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "first_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    temperature=0.0,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_GENERAL},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ],\n",
    "    functions=to_descriptions_list(available_functions),\n",
    "    function_call=\"auto\",  # Allow GPT to decide whether to use a function or not\n",
    "    # function_call={\"name\": \"make_new_function\"},  # Force using the specified function\n",
    "    # function_call='none',  # Force NOT using any functions\n",
    ")\n",
    "print(first_response[\"choices\"][0])\n",
    "print(\"---------------\")\n",
    "print(\n",
    "    \"Requested Function:\\n\",\n",
    "    first_response[\"choices\"][0][\"message\"][\"function_call\"][\"arguments\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3906d93c-4cc5-40b4-9133-57986f8b1237",
   "metadata": {},
   "source": [
    "---\n",
    "Here, GPT is correctly choosing to request a new function. \n",
    "\n",
    "Note: If you have difficulty getting GPT to use your function, you can force it to by specifying e.g. `function_call={\"name\": \"make_new_function\"}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee68b36-659c-41b5-9cb0-ef8b752a4fc4",
   "metadata": {},
   "source": [
    "## Make the requested function\n",
    "Now use our `make_new_function` from above to generate the requested function and add it to the list of `available_functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2128593b-34a0-43eb-9221-d85136029f8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New function added:\n",
      "def multiply_numbers(numbers: List[float]) -> float:\n",
      "    \"\"\"\n",
      "    Multiplies together all the numbers in the given array.\n",
      "\n",
      "    Args:\n",
      "        numbers: A list of numbers.\n",
      "\n",
      "    Returns:\n",
      "        The product of all the numbers in the list.\n",
      "    \"\"\"\n",
      "    product = 1\n",
      "    for num in numbers:\n",
      "        product *= num\n",
      "    return product\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the function_call GPT requested\n",
    "function_request_message = first_response[\"choices\"][0][\"message\"]\n",
    "new_func_arguments = json.loads(function_request_message[\"function_call\"][\"arguments\"])\n",
    "new_func_name = new_func_arguments[\"function_name\"]\n",
    "\n",
    "# Carry out the request\n",
    "new_func = make_new_function(\n",
    "    **new_func_arguments,\n",
    ")\n",
    "\n",
    "# Add the new function to the list of available functions\n",
    "available_functions[new_func_name] = {\n",
    "    \"func\": new_func,\n",
    "    \"description\": get_json_representation(new_func),\n",
    "}\n",
    "\n",
    "# Let's see what function we just added\n",
    "print(f\"New function added:\\n{inspect.getsource(new_func)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd75bcd5-daf8-4861-8b68-c981d1f44ea2",
   "metadata": {},
   "source": [
    "## Request response with updated available functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ed385a6-721e-4798-8d7b-bfe4772b63bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next response from Chat model:\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"multiply_numbers\",\n",
      "    \"arguments\": \"{\\n  \\\"numbers\\\": [3, 2, 6, 3, 6, 5, 4, 3, 6]\\n}\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_GENERAL},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "        # Note: No need to include the message requesting the new func - treat this as the first request again\n",
    "    ],\n",
    "    functions=to_descriptions_list(available_functions),\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "print(f\"Next response from Chat model:\\n{second_response['choices'][0]['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a3bf56-d859-4ed6-a19c-5e2cb4cc6f8f",
   "metadata": {},
   "source": [
    "---\n",
    "Excellent, now GPT wants to use the function it just created for itself!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d82352-4bc7-4d55-a0ac-aa262294bdfc",
   "metadata": {},
   "source": [
    "## Get the response from the requested function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "642b0075-d999-432b-94f9-aa5e179fa5c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function output:\n",
      "233280\n"
     ]
    }
   ],
   "source": [
    "# Extract the returned message\n",
    "function_call_message = second_response[\"choices\"][0][\"message\"]\n",
    "\n",
    "# From that message, get the name of the function called\n",
    "function_name = function_call_message[\"function_call\"][\"name\"]\n",
    "\n",
    "# Also get the arguments (this is a string representation of a JSON dict of arguments)\n",
    "arguments = json.loads(function_call_message[\"function_call\"][\"arguments\"])\n",
    "\n",
    "# Make the call to the function with the arguments that GPT decided\n",
    "function_response = available_functions[function_name][\"func\"](**arguments)\n",
    "\n",
    "# Look at what the function returned\n",
    "print(f\"Function output:\\n{function_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c40a0-fb8f-4b22-b90a-199466459add",
   "metadata": {},
   "source": [
    "## Convert response into message that GPT understands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e5dfbc7-1faf-4cfc-b545-4368fee208c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_response_message = {\n",
    "    \"role\": \"function\",\n",
    "    \"name\": function_name,\n",
    "    \"content\": str(function_response),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d276e65a-35f9-4cf7-8f1c-2e11f04f3cb9",
   "metadata": {},
   "source": [
    "## Call back to openai including the extra info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9da22f43-b71d-42e7-be9b-f9b24dac96bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of multiplying together all of these numbers [3, 2, 6, 3, 6, 5, 4, 3, 6] is 233280.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_GENERAL},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "        # Add the context of the previous function call and response\n",
    "        function_call_message,\n",
    "        function_response_message,\n",
    "    ],\n",
    ")\n",
    "final_response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bcd70-ca27-49ba-ad85-4e8ebd3bc69a",
   "metadata": {},
   "source": [
    "# Make autonomous GPT\n",
    "\n",
    "This makes the demo shown at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6f9bd7b-d67c-42ad-a007-75ba39f01c59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mThis is red text\u001b[0m\n",
      "\u001b[32mThis is green text\u001b[0m\n",
      "\u001b[33mThis is yellow text\u001b[0m\n",
      "\u001b[34mThis is blue text\u001b[0m\n",
      "\u001b[35mThis is magenta text\u001b[0m\n",
      "\u001b[36mThis is cyan text\u001b[0m\n",
      "\u001b[37mThis is white text\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def print_colored_text(text, color):\n",
    "    \"\"\"\n",
    "    Print colored text in JupyterLab output.\n",
    "    Available colors: 'red', 'green', 'yellow', 'blue', 'magenta', 'cyan', 'white'\n",
    "    \"\"\"\n",
    "    color_code = {\n",
    "        \"red\": \"\\x1b[31m\",\n",
    "        \"green\": \"\\x1b[32m\",\n",
    "        \"yellow\": \"\\x1b[33m\",\n",
    "        \"blue\": \"\\x1b[34m\",\n",
    "        \"magenta\": \"\\x1b[35m\",\n",
    "        \"cyan\": \"\\x1b[36m\",\n",
    "        \"white\": \"\\x1b[37m\",\n",
    "    }\n",
    "    reset_code = \"\\x1b[0m\"\n",
    "\n",
    "    if color not in color_code:\n",
    "        raise ValueError(\n",
    "            f\"Invalid color. Available colors: {', '.join(color_code.keys())}\"\n",
    "        )\n",
    "\n",
    "    colored_text = f\"{color_code[color]}{text}{reset_code}\"\n",
    "    print(colored_text)\n",
    "\n",
    "\n",
    "# Example usage\n",
    "colors = [\"red\", \"green\", \"yellow\", \"blue\", \"magenta\", \"cyan\", \"white\"]\n",
    "for color in colors:\n",
    "    print_colored_text(f\"This is {color} text\", color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b233e9d8-11c3-4a67-9005-7bb7c420d704",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_available_functions = {}\n",
    "\n",
    "\n",
    "def init_available_functions(clean_slate=False):\n",
    "    global global_available_functions\n",
    "    if clean_slate is False and global_available_functions:\n",
    "        return global_available_functions\n",
    "    else:\n",
    "        global_available_functions = {\n",
    "            \"make_new_function\": {\n",
    "                \"func\": make_new_function,\n",
    "                \"description\": MAKE_NEW_FUNCTION_DESCRIPTION,\n",
    "            }\n",
    "        }\n",
    "        return global_available_functions\n",
    "\n",
    "\n",
    "def get_response(messages: list[dict], functions: list[dict] = None) -> dict:\n",
    "    function_call = \"auto\" if functions is not None else \"none\"\n",
    "    return openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        temperature=0.0,\n",
    "        messages=messages,\n",
    "        functions=to_descriptions_list(functions),\n",
    "        function_call=function_call,\n",
    "    )\n",
    "\n",
    "\n",
    "def is_function_call(response: dict) -> bool:\n",
    "    return response[\"choices\"][0][\"finish_reason\"] == \"function_call\"\n",
    "\n",
    "\n",
    "def get_message(response: dict) -> dict:\n",
    "    return response[\"choices\"][0][\"message\"]\n",
    "\n",
    "\n",
    "def ask_autonomous_gpt(\n",
    "    question: str, clean_slate=True, verbose=True, max_steps=5\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Ask chatGPT a question, and it will decide to make new functions when necessary to answer your question.\n",
    "    Args:\n",
    "        question: The overall question to answer\n",
    "        clean_slate: Should it remember previously written functions, or start from a clean slate?\n",
    "        verbose: Have it print messages as it goes (otherwise only returns the final answer)\n",
    "        max_steps: Max number of times to loop (to prevent getting stuck in a loop and using all your credit!)\n",
    "    \"\"\"\n",
    "    available_functions = init_available_functions(clean_slate=clean_slate)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_GENERAL},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "\n",
    "    if verbose:\n",
    "        print_colored_text(f\"I've been asked to answer:\", \"green\")\n",
    "        print_colored_text(question, \"white\")\n",
    "\n",
    "    step = 0\n",
    "    while step <= max_steps:\n",
    "        step += 1\n",
    "        response = get_response(messages, available_functions)\n",
    "        message = get_message(response)\n",
    "        if is_function_call(response):\n",
    "            func_call = message[\"function_call\"]\n",
    "            func_name = func_call[\"name\"]\n",
    "            func_args = json.loads(func_call[\"arguments\"])\n",
    "            if func_name == \"make_new_function\":\n",
    "                new_func_name = func_args[\"function_name\"]\n",
    "                if verbose:\n",
    "                    print_colored_text(\n",
    "                        f\"Hmm, I think I'll first make a function called `{new_func_name}` to help out with this\",\n",
    "                        \"green\",\n",
    "                    )\n",
    "                new_func = make_new_function(**func_args)\n",
    "                if verbose:\n",
    "                    print_colored_text(\n",
    "                        f\"I made this function:\",\n",
    "                        \"green\",\n",
    "                    )\n",
    "                    print_colored_text(\n",
    "                        inspect.getsource(new_func),\n",
    "                        \"magenta\",\n",
    "                    )\n",
    "\n",
    "                available_functions[new_func_name] = {\n",
    "                    \"func\": new_func,\n",
    "                    \"description\": get_json_representation(new_func),\n",
    "                }\n",
    "                # Note: don't add anything to messages on purpose here (we just pretend the function already existed next time around)\n",
    "                continue\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print_colored_text(\n",
    "                        f\"I think I should use the `{new_func_name}` function with these arguments:\\n{func_args}\",\n",
    "                        \"green\",\n",
    "                    )\n",
    "                function_response = available_functions[func_name][\"func\"](**func_args)\n",
    "                if verbose:\n",
    "                    print_colored_text(\n",
    "                        f\"{func_name} returned: {str(function_response)}\", \"blue\"\n",
    "                    )\n",
    "                    print_colored_text(\n",
    "                        f\"I'll keep that in mind as I move forward\", \"green\"\n",
    "                    )\n",
    "                function_response_message = {\n",
    "                    \"role\": \"function\",\n",
    "                    \"name\": func_name,\n",
    "                    \"content\": str(function_response),\n",
    "                }\n",
    "                messages.append(message)\n",
    "                messages.append(function_response_message)\n",
    "                continue\n",
    "        else:\n",
    "            answer = message[\"content\"]\n",
    "            if verbose:\n",
    "                if step <= 1:\n",
    "                    print_colored_text(\n",
    "                        f\"I think I can just answer this question directly:\", \"green\"\n",
    "                    )\n",
    "                else:\n",
    "                    print_colored_text(\n",
    "                        f\"I think I am ready to answer, here goes:\", \"green\"\n",
    "                    )\n",
    "                print_colored_text(answer, \"cyan\")\n",
    "            return answer\n",
    "    if verbose:\n",
    "        print_colored_text(\n",
    "            f\"I have failed to get to the answer soon enough :( You can try increasing max_steps from {max_steps} to a higher number, but the problem may just be too hard for me...\",\n",
    "            \"green\",\n",
    "        )\n",
    "    raise RuntimeError(f\"Failed to reach a final answer within {max_steps} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3386c370-c3e1-485d-81ae-f72a1f92dcb7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mI've been asked to answer:\u001b[0m\n",
      "\u001b[37mGenerate a list of the first 10 fibonnaci numbers starting from 1? Then what is the product of those 10 numbers? And finally, how many digits are in that answer?\u001b[0m\n",
      "{\n",
      "  \"name\": \"make_new_function\",\n",
      "  \"arguments\": \"{\\n  \\\"function_name\\\": \\\"fibonacci_sequence\\\",\\n  \\\"arg_descriptions\\\": \\\"n: number\\\",\\n  \\\"description\\\": \\\"Generates a list of the first n Fibonacci numbers\\\"\\n}\"\n",
      "}\n",
      "\u001b[32mHmm, I think I'll first make a function called `fibonacci_sequence` to help out with this\u001b[0m\n",
      "\u001b[32mI made this function:\u001b[0m\n",
      "\u001b[35mdef fibonacci_sequence(n: int) -> List[int]:\n",
      "    \"\"\"\n",
      "    Generates a list of the first n Fibonacci numbers\n",
      "\n",
      "    Args:\n",
      "        n (int): The number of Fibonacci numbers to generate\n",
      "\n",
      "    Returns:\n",
      "        List[int]: A list of the first n Fibonacci numbers\n",
      "    \"\"\"\n",
      "    fib_sequence = [0, 1]\n",
      "    while len(fib_sequence) < n:\n",
      "        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n",
      "    return fib_sequence[:n]\n",
      "\u001b[0m\n",
      "{\n",
      "  \"name\": \"fibonacci_sequence\",\n",
      "  \"arguments\": \"{\\n  \\\"n\\\": 10\\n}\"\n",
      "}\n",
      "\u001b[32mI think I should use the `fibonacci_sequence` function with these arguments:\n",
      "{'n': 10}\u001b[0m\n",
      "\u001b[34mfibonacci_sequence returned: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\u001b[0m\n",
      "\u001b[32mI'll keep that in mind as I move forward\u001b[0m\n",
      "{\n",
      "  \"name\": \"make_new_function\",\n",
      "  \"arguments\": \"{\\n  \\\"function_name\\\": \\\"product\\\",\\n  \\\"arg_descriptions\\\": \\\"a list of numbers\\\",\\n  \\\"description\\\": \\\"Calculates the product of all numbers in the given list\\\"\\n}\"\n",
      "}\n",
      "\u001b[32mHmm, I think I'll first make a function called `product` to help out with this\u001b[0m\n",
      "\u001b[32mI made this function:\u001b[0m\n",
      "\u001b[35mdef product(numbers: List[float]) -> float:\n",
      "    \"\"\"\n",
      "    Calculates the product of all numbers in the given list.\n",
      "\n",
      "    Args:\n",
      "        numbers: A list of numbers.\n",
      "\n",
      "    Returns:\n",
      "        The product of all numbers in the list.\n",
      "    \"\"\"\n",
      "    result = 1\n",
      "    for num in numbers:\n",
      "        result *= num\n",
      "    return result\n",
      "\u001b[0m\n",
      "{\n",
      "  \"name\": \"product\",\n",
      "  \"arguments\": \"{\\n  \\\"numbers\\\": [1, 1, 2, 3, 5, 8, 13, 21, 34]\\n}\"\n",
      "}\n",
      "\u001b[32mI think I should use the `product` function with these arguments:\n",
      "{'numbers': [1, 1, 2, 3, 5, 8, 13, 21, 34]}\u001b[0m\n",
      "\u001b[34mproduct returned: 2227680\u001b[0m\n",
      "\u001b[32mI'll keep that in mind as I move forward\u001b[0m\n",
      "{\n",
      "  \"name\": \"make_new_function\",\n",
      "  \"arguments\": \"{\\n  \\\"function_name\\\": \\\"count_digits\\\",\\n  \\\"arg_descriptions\\\": \\\"a number\\\",\\n  \\\"description\\\": \\\"Counts the number of digits in a given number\\\"\\n}\"\n",
      "}\n",
      "\u001b[32mHmm, I think I'll first make a function called `count_digits` to help out with this\u001b[0m\n",
      "\u001b[32mI made this function:\u001b[0m\n",
      "\u001b[35mdef count_digits(number: int) -> int:\n",
      "    \"\"\"\n",
      "    Counts the number of digits in a given number.\n",
      "\n",
      "    Args:\n",
      "        number (int): The number to count the digits of.\n",
      "\n",
      "    Returns:\n",
      "        int: The number of digits in the given number.\n",
      "    \"\"\"\n",
      "    return len(str(number))\n",
      "\u001b[0m\n",
      "{\n",
      "  \"name\": \"count_digits\",\n",
      "  \"arguments\": \"{\\n  \\\"number\\\": 2227680\\n}\"\n",
      "}\n",
      "\u001b[32mI think I should use the `count_digits` function with these arguments:\n",
      "{'number': 2227680}\u001b[0m\n",
      "\u001b[34mcount_digits returned: 7\u001b[0m\n",
      "\u001b[32mI'll keep that in mind as I move forward\u001b[0m\n",
      "\u001b[32mI think I am ready to answer, here goes:\u001b[0m\n",
      "\u001b[36mThe first 10 Fibonacci numbers starting from 1 are: [0, 1, 1, 2, 3, 5, 8, 13, 21, 34].\n",
      "The product of these 10 numbers is 2,227,680.\n",
      "The answer has 7 digits.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# user_request = \"What is the result of multiplying together all of these numbers [3,2,6,3,6,5,4,3,6]?\"\n",
    "# user_request = \"How many letters are in this question?\"\n",
    "# user_request = \"List out the first 10 fibonnaci numbers? Then what is the product of those 10 numbers? And finally, how many digits are in that answer?\"\n",
    "user_request = \"Generate a list of the first 10 fibonnaci numbers starting from 1? Then what is the product of those 10 numbers? And finally, how many digits are in that answer?\"\n",
    "final_answer = ask_autonomous_gpt(user_request, verbose=True, max_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "aeb813f1-2c30-4ca9-a494-8ef76730d8d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'make_new_function': {'func': <function __main__.make_new_function(function_name: str, arg_descriptions: str, description: str) -> Callable>,\n",
       "  'description': {'name': 'make_new_function',\n",
       "   'description': \"Use this if an existing function doesn't exist, and it would be helpful to have a new function to complete a task. The new function will be made to carry out the task described in the `description` given the arguments described by `arg_descriptions`\",\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'function_name': {'type': 'string'},\n",
       "     'arg_descriptions': {'type': 'string'},\n",
       "     'description': {'type': 'string'}},\n",
       "    'required': ['function_name', 'arg_descriptions', 'description']},\n",
       "   'returns': {'type': 'callable'}}},\n",
       " 'is_prime': {'func': <function temporary.is_prime(n: int) -> bool>,\n",
       "  'description': {'name': 'is_prime',\n",
       "   'description': 'Checks if a number is prime',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'n': {'type': 'number',\n",
       "      'description': 'The number to check'}},\n",
       "    'required': ['n']},\n",
       "   'returns': {'type': 'boolean',\n",
       "    'description': 'True if the number is prime, False otherwise'}}}}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global_available_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295aedb4-c7f0-4d81-97ca-778938daf49b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165accd0-34de-4e4b-bb97-3995962ee533",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
