{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5fa509e9-5226-4967-a80f-7a5f01bba028",
   "metadata": {},
   "source": [
    "# Set-up API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a0e4ae2-5d10-464f-a8c7-8da99d48285f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "with open(\"../API_KEY\", \"r\") as f:\n",
    "    key = f.read()\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5d36a5-d2f2-4682-ab2c-c3a31c8f38b8",
   "metadata": {},
   "source": [
    "# General Plan:\n",
    "## TODO: rewrite this and all following Markdown cells\n",
    "- Make a function that converts a python function into the json representation required by openai\n",
    "- Then allow for making a chain where GPT mostly creates functions for itself:\n",
    "    - Get gpt to make a function\n",
    "    - Get gpt to save that function in a folder along with the json representation of the function\n",
    "    - Automatically include all tools in the folder (i.e. using the json representations, but then being able to call the functions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3daa420-25c9-4739-8aa1-d31c38c34517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Putting a few long functions in here if they aren't important for the main story\n",
    "import demo_functions\n",
    "\n",
    "# Other things that will be used later\n",
    "import json\n",
    "import numpy as np\n",
    "import inspect\n",
    "import os\n",
    "import importlib.util\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a1ef92-60b9-43b8-af8f-e9711c1762b2",
   "metadata": {},
   "source": [
    "## First, let's test out the function calling\n",
    "\n",
    "Make a very basic function first\n",
    "\n",
    "# TODO: Make this function add some extra info that the LLM doesn't already have to make it more obvious that the function call can be helpful in some way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb27a074-def7-4fcf-8b25-a2fd3b205e5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple example function for initial testing\n",
    "def get_weather_report(day_of_week: int, weather_type: str, temperature: float = 10.0) -> str:\n",
    "    \"\"\"\n",
    "    Converts information about weather into a string representation.\n",
    "\n",
    "    Args:\n",
    "        day_of_week (int): The day of the week from 0 to 6.\n",
    "        weather_type (str): The type of weather, can be \"sunny\", \"rainy\", or \"windy\".\n",
    "        temperature (float, optional): Temperature in Celsius. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the weather report.\n",
    "    \"\"\"\n",
    "    return f'For the {day_of_week}th day of the week, the weather is predicted to be {weather_type} with a max temperature of {temperature}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0164fadb-9d41-4708-b668-10d6fb6874d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "WEATHER_REPORT_DESCRIPTION = {\n",
    "    \"name\": \"get_weather_report\",\n",
    "    \"description\": \"Converts information about weather into a string representation\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"day_of_week\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The day of the week from 0 to 6\",\n",
    "            },\n",
    "            \"weather_type\": {\"type\": \"string\", \"enum\": [\"sunny\", \"rainy\", \"windy\"]},\n",
    "            \"temperature\": {\"type\": \"number\", \"description\": \"Temperature in Celsius. Defaults to 10.0.\"},\n",
    "        },\n",
    "        \"required\": [\"day_of_week\", \"weather_type\"],\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d41eb1d-b864-46f2-abb8-17c8fe8291e5",
   "metadata": {},
   "source": [
    "Test using this with the new openai `function_call` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeb37cb5-fe1d-4ffd-8978-14b40a48e3bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7S7oxKY3SeQqFLbk8ehkjGDGKdSSl at 0x1e18c0a97f0> JSON: {\n",
       "  \"id\": \"chatcmpl-7S7oxKY3SeQqFLbk8ehkjGDGKdSSl\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1686937603,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": null,\n",
       "        \"function_call\": {\n",
       "          \"name\": \"get_weather_report\",\n",
       "          \"arguments\": \"{\\n  \\\"day_of_week\\\": 2,\\n  \\\"weather_type\\\": \\\"sunny\\\",\\n  \\\"temperature\\\": 36.4\\n}\"\n",
       "        }\n",
       "      },\n",
       "      \"finish_reason\": \"function_call\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 118,\n",
       "    \"completion_tokens\": 36,\n",
       "    \"total_tokens\": 154\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"It's currently a sunny 36.4C this Tuesday, can you give me a weather report?\"}],\n",
    "    functions=[\n",
    "        WEATHER_REPORT_DESCRIPTION,\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "first_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adde660b-8e94-46aa-90b5-3546d0853ce5",
   "metadata": {},
   "source": [
    "We can see that a `function_call` was made (rather than returning `content`)\n",
    "\n",
    "Now, we need to handle the function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8be6434e-2f88-4f01-8894-2793eace7412",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function output:\n",
      "For the 2th day of the week, the weather is predicted to be sunny with a max temperature of 36.4\n"
     ]
    }
   ],
   "source": [
    "# Extract the returned message\n",
    "first_message = first_response['choices'][0]['message']\n",
    "\n",
    "# From that message, get the name of the function called\n",
    "function_name = first_message[\"function_call\"][\"name\"]\n",
    "\n",
    "# Also get the arguments (this is a string representation of a JSON dict of arguments)\n",
    "arguments = first_message['function_call'].get('arguments')\n",
    "\n",
    "# Make the call to the function with the arguments that the LLM decided\n",
    "function_response = get_weather_report(\n",
    "    **json.loads(arguments),  # Unpack the arguments as keyword: value pairs\n",
    ")\n",
    "\n",
    "# Look at what the function returned\n",
    "print(f'Function output:\\n{function_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868cea2e-ddfa-43af-a45f-da1a5c04727c",
   "metadata": {},
   "source": [
    "And then, pass that result back to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8761dad-1930-425b-83e2-39b21d47eeaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7S7pB9SYLdEvKVloxXuTTBnguGPqG at 0x1e18c95fb30> JSON: {\n",
       "  \"id\": \"chatcmpl-7S7pB9SYLdEvKVloxXuTTBnguGPqG\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1686937617,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"Celsius. It's going to be a sunny day with a temperature of 36.4 degrees Celsius. Enjoy the weather!\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 97,\n",
       "    \"completion_tokens\": 26,\n",
       "    \"total_tokens\": 123\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response_message = {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": function_response,\n",
    "        }\n",
    "\n",
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"It's currently 36.4C this Tuesday, can you give me a weather report?\"},\n",
    "        first_message,  # Pass in the context (i.e. that it previously requested a function_call\n",
    "        function_response_message,  # And the result of that function call\n",
    "    ],\n",
    ")\n",
    "second_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "181c93cb-a565-4a0b-8f69-6a157783549a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Celsius. It's going to be a sunny day with a temperature of 36.4 degrees Celsius. Enjoy the weather!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74558f70-d566-4154-92aa-c810843b4b55",
   "metadata": {},
   "source": [
    "TODO: Add some description of what we see overall here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e2200f-10d1-45f2-b612-d5ce841d3ce7",
   "metadata": {},
   "source": [
    "# Automate making the JSON description of existing functions you want GPT to use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76356881-fef7-4dc2-af33-7fea62008a0b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Can try make conversion using fixed code \n",
    "(For this, you really have to think about all the possible formats the existing functions may have)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a147eb89-6d79-4d7b-bdd3-8643597102dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather_report',\n",
       " 'description': 'Converts information about weather into a string representation.',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'day_of_week': {'type': 'number',\n",
       "    'description': 'The day of the week from 0 to 6.'},\n",
       "   'weather_type': {'type': 'string',\n",
       "    'description': 'The type of weather, can be \"sunny\", \"rainy\", or \"windy\".'},\n",
       "   'temperature': {'type': 'number',\n",
       "    'description': 'Temperature in Celsius. Defaults to 10.0.'}},\n",
       "  'required': ['day_of_week', 'weather_type']}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_json_representation = demo_functions.get_json_representation_using_code\n",
    "get_json_representation(get_weather_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1972ef6-cd34-46db-9d2d-d7d97c0d53bf",
   "metadata": {},
   "source": [
    "## Or can make GPT do the conversion for us\n",
    "Won't be 100% deterministic, but will handle varying existing code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a41d7118-736c-4f93-aee1-a787a78327a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "from typing import Callable\n",
    "\n",
    "SYSTEM_PROMPT_JSON_REP = '''Your job is to convert a python function into a json representation with a specific form.\n",
    "For example, given this function:\n",
    "```\n",
    "def get_weather_report(day_of_week: int, weather_type: str, temperature: float = 10.0) -> str:\n",
    "    \"\"\"\n",
    "    Converts information about weather into a string representation.\n",
    "\n",
    "    Args:\n",
    "        day_of_week (int): The day of the week from 0 to 6.\n",
    "        weather_type (str): The type of weather, can be \"sunny\", \"rainy\", or \"windy\".\n",
    "        temperature (float, optional): Temperature in Celsius. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the weather report.\n",
    "    \"\"\"\n",
    "    return f'For the {day_of_week}th day of the week, the weather is predicted to be {weather_type} with a max temperature of {temperature}'\n",
    "```\n",
    "\n",
    "You should return:\n",
    "```\n",
    "{\n",
    "    \"name\": \"get_weather_report\",\n",
    "    \"description\": \"Converts information about weather into a string representation\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"day_of_week\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The day of the week from 0 to 6\",\n",
    "            },\n",
    "            \"weather_type\": {\"type\": \"string\", \"enum\": [\"sunny\", \"rainy\", \"windy\"]},\n",
    "            \"temperature\": {\"type\": \"number\", \"description\": \"Temperature in Celsius. Defaults to 10.0.\"},\n",
    "        },\n",
    "        \"required\": [\"day_of_week\", \"weather_type\"],\n",
    "    },\n",
    "}\n",
    "```\n",
    "Return the JSON ONLY.''' \n",
    "\n",
    "\n",
    "def get_json_representation(func: Callable) -> dict:\n",
    "    \"\"\"\n",
    "    Uses the openai.ChatCompletion.create endpoint to return the necessary imports for a function supplied as a string.\n",
    "\n",
    "    Args:\n",
    "        function_str (str): The function for which to get the necessary imports, supplied as a string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string of the necessary imports for the function.\n",
    "    \"\"\"\n",
    "    # Set up the request to OpenAI\n",
    "    parameters = {\n",
    "        'model': 'gpt-3.5-turbo-0613',\n",
    "        'temperature': 0.0,  # Deterministic output (most probable next word every time)\n",
    "        'messages': [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_JSON_REP},  # Pass in the initial instructions\n",
    "            {\"role\": \"user\", \"content\": inspect.getsource(func)}  # Then give the func code\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Ask OpenAI to make the conversion to JSON format\n",
    "    response = openai.ChatCompletion.create(**parameters)\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    assistant_response = response['choices'][0]['message']['content']\n",
    "\n",
    "    return json.loads(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9edb8bc0-f845-4904-abcc-056eea7012cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def get_weather_report(day_of_week: int, weather_type: str, temperature: float = 10.0) -> str:\n",
      "    \"\"\"\n",
      "    Converts information about weather into a string representation.\n",
      "\n",
      "    Args:\n",
      "        day_of_week (int): The day of the week from 0 to 6.\n",
      "        weather_type (str): The type of weather, can be \"sunny\", \"rainy\", or \"windy\".\n",
      "        temperature (float, optional): Temperature in Celsius. Defaults to 10.0.\n",
      "\n",
      "    Returns:\n",
      "        str: A string representation of the weather report.\n",
      "    \"\"\"\n",
      "    return f'For the {day_of_week}th day of the week, the weather is predicted to be {weather_type} with a max temperature of {temperature}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: inspect just lets you see the source code of a function\n",
    "print(inspect.getsource(get_weather_report))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ab0bd1f-a2b1-4303-bdb9-8e7c25a4b54e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_weather_report',\n",
       " 'description': 'Converts information about weather into a string representation',\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'day_of_week': {'type': 'number',\n",
       "    'description': 'The day of the week from 0 to 6'},\n",
       "   'weather_type': {'type': 'string', 'enum': ['sunny', 'rainy', 'windy']},\n",
       "   'temperature': {'type': 'number',\n",
       "    'description': 'Temperature in Celsius. Defaults to 10.0.'}},\n",
       "  'required': ['day_of_week', 'weather_type']}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_json_representation(get_weather_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495bbac5-c0d5-4c83-851a-a27e97178126",
   "metadata": {},
   "source": [
    "Not surprising that it does well on this since we gave it this as an example as well, but we'll use it again later and see that it continues to work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece92a0-7140-41eb-b9b9-04bf1a92eca1",
   "metadata": {},
   "source": [
    "# TODO: Try out forcing gpt to fill a fake function_call with info (maybe better at returning json content with smaller prompt?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4375d-ca93-48cb-9a36-83b22adadac2",
   "metadata": {},
   "source": [
    "# Let's structure how we can store these tools\n",
    "\n",
    "- Store each function/tool in it's own `.py` file with the same name as the function\n",
    "    - We'll need to make sure we include the necessary `imports`\n",
    "- Store the JSON descriptions of the functions in a `.json` file with the same name as the function\n",
    "- Load the JSON descriptions from the `.json` files\n",
    "- Import and run the necessary functions from the `.py` files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316ac955-0d49-4dae-aa02-76d533328d5a",
   "metadata": {},
   "source": [
    "### Let's think about how we can save this example function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5d970cc-1e51-41e8-a82e-6a4f30b698e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"new_val\": 0.1411200080598672}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_func(d: dict, a: int, b: float) -> str:\n",
    "    \"\"\"\n",
    "    Calculates the sine of the product of a and b and adds it to the dictionary d with the key 'new_val'.\n",
    "\n",
    "    Args:\n",
    "      d: A dictionary to which the new value will be added.\n",
    "      a: An integer value.\n",
    "      b: A float value.\n",
    "\n",
    "    Returns:\n",
    "      A JSON string representation of the updated dictionary d.\n",
    "    \"\"\"\n",
    "    d['new_val'] = np.sin(a*b)\n",
    "    return json.dumps(d)\n",
    "\n",
    "test_func({}, 1, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ea31f8-312c-436d-803f-602269220b7e",
   "metadata": {},
   "source": [
    "If we want to save this to it's own file, we are going to need to include the imports for `json` and `np`.\n",
    "\n",
    "It should look something like \n",
    "\n",
    "%test_func.py\n",
    "```\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def test_func(d: dict, a: int, b: float) -> str:\n",
    "    \"\"\"\n",
    "    Calculates the sine of the product of a and b and adds it to the dictionary d with the key 'new_val'.\n",
    "\n",
    "    Args:\n",
    "      d: A dictionary to which the new value will be added.\n",
    "      a: An integer value.\n",
    "      b: A float value.\n",
    "\n",
    "    Returns:\n",
    "      A JSON string representation of the updated dictionary d.\n",
    "    \"\"\"\n",
    "    d['new_val'] = np.sin(a*b)\n",
    "    return json.dumps(d)\n",
    "\n",
    "test_func({}, 1, 3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b5f50a-ce93-48a4-b7ea-3e688ed82cdc",
   "metadata": {},
   "source": [
    "How can we automate the process of figuring out what imports are necessary (not very simple since some imports require knowledge that e.g. `np` is just the shorthand name of `numpy`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9c1f0-c52f-4ef1-a363-7ebf7690e401",
   "metadata": {},
   "source": [
    "### Figure out the necessary imports for a function\n",
    "\n",
    "This is again a fairly difficult task to accomplish with code, but we can get GPT to help us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2fca427f-f9fd-4965-809e-cd57d1f1564e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_IMPORTS_REQUIRED = '''Your job is to return ONLY the python imports that would be required to run the function given by the user. For example:\n",
    "-----\n",
    "The user has given you this function:\n",
    "```\n",
    "def some_function(a, b, **kwargs):\n",
    "    c = np.sin(a+b)\n",
    "    result = {'input_a': a, 'input_b': b, 'res': c}\n",
    "    return json.dumps(result)\n",
    "```\n",
    "You should return:\n",
    "```\n",
    "import numpy as np\n",
    "import json\n",
    "```\n",
    "-----\n",
    "\n",
    "Do not include ANY other text other than the imports required. If no imports are required return \"No imports required\".\n",
    "'''\n",
    "\n",
    "def get_imports_for_function(function_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the openai.ChatCompletion.create endpoint to return the necessary imports for a function supplied as a string.\n",
    "\n",
    "    Args:\n",
    "        function_str (str): The function for which to get the necessary imports, supplied as a string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string of the necessary imports for the function.\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'model': 'gpt-3.5-turbo-0613',\n",
    "        'temperature': 0.0,\n",
    "        'messages': [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_IMPORTS_REQUIRED},\n",
    "            {\"role\": \"user\", \"content\": function_str}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = openai.ChatCompletion.create(**parameters)\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    assistant_response = response['choices'][0]['message']['content']\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93986ee-026f-46b0-bed1-adf1c0850bf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def test_func(d: dict, a: int, b: float) -> str:\n",
      "    \"\"\"\n",
      "    Calculates the sine of the product of a and b and adds it to the dictionary d with the key 'new_val'.\n",
      "\n",
      "    Args:\n",
      "      d: A dictionary to which the new value will be added.\n",
      "      a: An integer value.\n",
      "      b: A float value.\n",
      "\n",
      "    Returns:\n",
      "      A JSON string representation of the updated dictionary d.\n",
      "    \"\"\"\n",
      "    d['new_val'] = np.sin(a*b)\n",
      "    return json.dumps(d)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "func_str = inspect.getsource(test_func)\n",
    "print(func_str)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a25a5964-341c-49a3-8861-a63ec86b1d08",
   "metadata": {},
   "source": [
    "Function only, missing the imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8518dba-9e23-480a-b8d2-6ece39fa53d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import json\n"
     ]
    }
   ],
   "source": [
    "imports = get_imports_for_function(func_str)\n",
    "print(imports)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611f9cbe-093a-481d-bde2-d826a341f0fc",
   "metadata": {},
   "source": [
    "GPT has figured out the imports for us :)\n",
    "\n",
    "Let's check what happens if there are no imports required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724f054a-1aef-4833-987a-52ebbdbd3260",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_func2(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Multiplies two float values and returns the result.\n",
    "\n",
    "    Args:\n",
    "      a: A float value.\n",
    "      b: A float value.\n",
    "\n",
    "    Returns:\n",
    "      The product of a and b.\n",
    "    \"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42021ad4-b535-4f8a-a71f-8e593b33d9a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'No imports required.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_imports_for_function(inspect.getsource(test_func2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198a5549-cb62-4b4b-9cf5-f5d5ee60a168",
   "metadata": {},
   "source": [
    "Perfect, that's what we asked GPT to do in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe34d07-5755-47df-8905-82bbf4c9e315",
   "metadata": {},
   "source": [
    "### Now let's save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9330a898-6882-4735-9aa6-b68d9f0cd821",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_func_and_json(func: Callable, func_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the given function and its JSON representation to a subfolder of func_folder.\n",
    "\n",
    "    Args:\n",
    "        func (Callable): The function to save.\n",
    "        func_folder (str): The path to the folder where the function and JSON representation will be saved.\n",
    "    \"\"\"\n",
    "    func_str = inspect.getsource(func)\n",
    "    # Get the imports required for the function\n",
    "    imports_string = get_imports_for_function(func_str)\n",
    "    if 'no imports required' in imports_string.lower():\n",
    "        imports_string = ''\n",
    "    else:\n",
    "        imports_string += '\\n\\n\\n'\n",
    "        \n",
    "    file_contents = imports_string+func_str\n",
    "    \n",
    "    # Save function to .py file\n",
    "    with open(f\"{func_folder}/{func.__name__}.py\", \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "\n",
    "    # Save JSON representation to .json file\n",
    "    with open(f\"{func_folder}/{func.__name__}.json\", \"w\") as f:\n",
    "        json.dump(get_json_representation(func), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e66c9537-b746-4f83-99ab-772f64985450",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "FUNCTIONS_FOLDER = 'functions'\n",
    "os.makedirs(FUNCTIONS_FOLDER, exist_ok=True)\n",
    "\n",
    "save_func_and_json(test_func, func_folder=FUNCTIONS_FOLDER)\n",
    "save_func_and_json(test_func2, func_folder=FUNCTIONS_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ffd73e-210b-4b0e-85fc-f03da50459a8",
   "metadata": {},
   "source": [
    "And now we have those functions saved in a nice format\n",
    "\n",
    "### Loading the functions for use by GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64e71018-f05c-41c8-bdf2-0b05552b2603",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_json_descriptions(directory: str) -> dict:\n",
    "    \"\"\"\n",
    "    Loads the contents of all the .json files in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory to load .json files from.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the key is the name of the json file (excluding the .json extension) and the value is the content of the .json file.\n",
    "    \"\"\"\n",
    "    json_data = {}\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file is a .json file\n",
    "        if filename.endswith(\".json\"):\n",
    "            # Remove the .json extension from the filename\n",
    "            name = filename[:-5]\n",
    "            # Open the .json file and load its contents\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                data = json.load(f)\n",
    "            # Add the data to the dictionary\n",
    "            json_data[name] = data\n",
    "\n",
    "    return json_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c22f9ab4-4331-4824-9b50-516074cb27e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved functions are: dict_keys(['multiply_list', 'multiply_numbers', 'test_func', 'test_func2'])\n",
      "\n",
      "\n",
      "test_func description: {\n",
      "    \"name\": \"test_func\",\n",
      "    \"description\": \"Calculates the sine of the product of a and b and adds it to the dictionary d with the key 'new_val'.\",\n",
      "    \"parameters\": {\n",
      "        \"type\": \"object\",\n",
      "        \"properties\": {\n",
      "            \"d\": {\n",
      "                \"type\": \"object\",\n",
      "                \"description\": \"A dictionary to which the new value will be added.\"\n",
      "            },\n",
      "            \"a\": {\n",
      "                \"type\": \"integer\",\n",
      "                \"description\": \"An integer value.\"\n",
      "            },\n",
      "            \"b\": {\n",
      "                \"type\": \"number\",\n",
      "                \"description\": \"A float value.\"\n",
      "            }\n",
      "        },\n",
      "        \"required\": [\n",
      "            \"d\",\n",
      "            \"a\",\n",
      "            \"b\"\n",
      "        ]\n",
      "    },\n",
      "    \"return\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"A JSON string representation of the updated dictionary d.\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "function_descriptions = load_json_descriptions(FUNCTIONS_FOLDER)\n",
    "print(f\"Saved functions are: {function_descriptions.keys()}\\n\\n\")\n",
    "# Using json.dumps just to make the output look nicer for us mere humans\n",
    "test_func_description = json.dumps(function_descriptions['test_func'], indent=4)\n",
    "print(f\"test_func description: {test_func_description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2911815c-321a-47ca-b42e-f470296222da",
   "metadata": {},
   "source": [
    "### And now to use a function from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c24ae96f-0744-4613-8b24-d51f53c381f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_function_from_file(folder: str, filename: str):\n",
    "    \"\"\"\n",
    "    Loads a function from a .py file.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory where the .py file is located.\n",
    "        filename (str): The name of the .py file (excluding the .py extension).\n",
    "\n",
    "    Returns:\n",
    "        function: The function contained in the .py file.\n",
    "    \"\"\"\n",
    "    # Create the path to the .py file\n",
    "    file_path = os.path.join(folder, filename + \".py\")\n",
    "\n",
    "    # Load the spec of the module\n",
    "    spec = importlib.util.spec_from_file_location(filename, file_path)\n",
    "\n",
    "    # Create a module from the spec\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "\n",
    "    # Execute the module to get the function\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    # Get the function from the module\n",
    "    function = getattr(module, filename)\n",
    "\n",
    "    return function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f4334e5-68c7-4251-a5b7-9bed714b4c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiply_list': <function multiply_list.multiply_list(numbers: List[float]) -> float>,\n",
       " 'multiply_numbers': <function multiply_numbers.multiply_numbers(numbers: List[float]) -> float>,\n",
       " 'test_func': <function test_func.test_func(d: dict, a: int, b: float) -> str>,\n",
       " 'test_func2': <function test_func2.test_func2(a: float, b: float) -> float>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_descriptions = load_json_descriptions(FUNCTIONS_FOLDER)\n",
    "funcs = {}\n",
    "for func_name in function_descriptions:\n",
    "    funcs[func_name] = load_function_from_file(FUNCTIONS_FOLDER, func_name)\n",
    "funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b097c7b-597e-4f09-bed3-d026126648d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"new_val\": -0.7568024953079282}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test with a similar example to what we did before\n",
    "funcs['test_func']({}, 1, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81af150-1e75-4377-b09f-79665004bfde",
   "metadata": {},
   "source": [
    "# Now let's provide a way for GPT to make it's own function, save it, and use it in its next response!\n",
    "\n",
    "- Make a write python code function (the function should just take a description of what the code needs to do so that a separate prompt can be used to actually generate the code)\n",
    "\n",
    "# TODO: Maybe can improve the code generator by making it fill in a fake function that takes args for 'signature', 'docstring', 'code body' or something like that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b7c906-dfbf-4e0a-8a5b-9853a785a4b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT_MAKE_NEW_FUNCTION = '''You are an expert python coder that will be tasked with generating the code to go in a .py file for a single function given some specific information from the user.\n",
    "You will be provided:\n",
    "    - function_name: The name to give the new function\n",
    "    - arg_descriptions: Descriptions of all the arguments the function should take (if their types are missing, try to infer them)\n",
    "    - description: What the function should do with the given arguments\n",
    "\n",
    "When generating the new function you should follow these rules:\n",
    "    - Include ONLY the text that will be in the python file (e.g. starting with `import ...` unless no imports are necessary in which case, starting with `def ...`)\n",
    "    - Do NOT include any plain text explanation at the end of the written code\n",
    "    - Use the latest python programming techniques and best practices\n",
    "    - Use the latest/best python libraries when appropriate (e.g. if plotting, use `plotly` instead of `matplotlib` because plotly is better library even though matplotlib is better known)\n",
    "    - Always include a google style docstring\n",
    "    - Include type hints for the inputs and output\n",
    "    - Include all necessary imports\n",
    "'''\n",
    "\n",
    "\n",
    "def make_new_function(function_name: str, arg_descriptions: str, description: str):\n",
    "    \"\"\"\n",
    "    Use this if an existing function doesn't exist, and it would be helpful to have a new function to complete a task. \n",
    "    The new function will be made to carry out the task described in the `description` given the arguments described by `arg_descriptions`\n",
    "    \n",
    "    Args:\n",
    "        function_name: Name to give the new function (should follow python naming conventions)\n",
    "        arg_descriptions: A description of any arguments that the function should take (including type, and default value if appropriate)\n",
    "        description: A description of what the function should do (including the what it should output)\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'model': 'gpt-3.5-turbo-0613',\n",
    "        'temperature': 0.0,\n",
    "        'messages': [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT_MAKE_NEW_FUNCTION},\n",
    "            {\"role\": \"user\", \"content\": f\"function_name: {function_name}\\narg_descriptions: {arg_descriptions}\\ndescription: {description}\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = openai.ChatCompletion.create(**parameters)\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    function_code = response['choices'][0]['message']['content']\n",
    "    return function_code\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdadbaf-419f-4edd-86f2-10b205ae8e81",
   "metadata": {},
   "source": [
    "## We need the JSON description again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5554badd-d463-44d4-a49e-315fedf11fc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'make_new_function',\n",
       " 'description': \"Use this if an existing function doesn't exist, and it would be helpful to have a new function to complete a task. The new function will be made to carry out the task described in the `description` given the arguments described by `arg_descriptions`\",\n",
       " 'parameters': {'type': 'object',\n",
       "  'properties': {'function_name': {'type': 'string'},\n",
       "   'arg_descriptions': {'type': 'string'},\n",
       "   'description': {'type': 'string'}},\n",
       "  'required': ['function_name', 'arg_descriptions', 'description']}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_new_function_description = get_json_representation(make_new_function)\n",
    "make_new_function_description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f31cc-dc8a-4869-95f7-063946941b79",
   "metadata": {},
   "source": [
    "## Let's test that out\n",
    "\n",
    "We'll ask for something that GPT is bad at doing by itself (like basic math)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dbf5acc9-d892-41ed-aa81-5f15a5c9ef0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7S7wZMoV0sMoTiB1E8BKU07e1s5SU at 0x1e18cd077d0> JSON: {\n",
       "  \"id\": \"chatcmpl-7S7wZMoV0sMoTiB1E8BKU07e1s5SU\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1686938075,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": null,\n",
       "        \"function_call\": {\n",
       "          \"name\": \"make_new_function\",\n",
       "          \"arguments\": \"{\\n  \\\"function_name\\\": \\\"multiply_numbers\\\",\\n  \\\"arg_descriptions\\\": \\\"a list of numbers\\\",\\n  \\\"description\\\": \\\"Multiply together all the numbers in the given list\\\"\\n}\"\n",
       "        }\n",
       "      },\n",
       "      \"finish_reason\": \"function_call\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 238,\n",
       "    \"completion_tokens\": 45,\n",
       "    \"total_tokens\": 283\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user_request = \"I'd like you to multiply a list of numbers together and return the total value, the list is [3,2,6,3,6,5,4,3,6].\"\n",
    "user_request = \"What is the result of multiplying together all of these numbers [3,2,6,3,6,5,4,3,6]?\"\n",
    "\n",
    "SYSTEM_PROMPT_GENERAL = '''You are a helpful AI assistant. \n",
    "When responding you should follow these rules:\n",
    " - You should ONLY consider using the functions provided (e.g. do not just assume you can use `python`)\n",
    " - You should always use functions as an intermediate step to respond to the user when appropriate (e.g. when being asked to do math, use a function to do the calculation)\n",
    " - If there is a missing function that would be useful, make a call to `make_new_function` to create it BEFORE responding to the user\n",
    "'''\n",
    "\n",
    "response_requesting_new_func = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_GENERAL},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "    ],\n",
    "    functions=[\n",
    "        make_new_function_description,\n",
    "    ],\n",
    "    function_call=\"auto\",  \n",
    "    # function_call={\"name\": \"make_new_function\"},  # Force using the function\n",
    ")\n",
    "response_requesting_new_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312c1cb2-84af-476f-8876-90dfb557e320",
   "metadata": {},
   "source": [
    "GPT-3.5 has a bit of a problem of hallucinating functions that don't exist (e.g. It often assumes it has a `python` function if you let it decide what to do automatically)\n",
    "If needs me, we can force it to use the `make_new_function` call by specifying `function_call={\"name\": \"make_new_function\"}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108bf608-24ed-4eb8-9511-d33b772795e6",
   "metadata": {},
   "source": [
    "### Now let's make the requested function and save to file\n",
    "# TODO: Refactor the write to file earlier so that I don't need duplicates here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "186916f2-ed92-409e-851d-0980e74843b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sanitize_python_code(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitizes a string containing Python code. If the code is surrounded by markdown triple backticks, they are removed.\n",
    "    Also, language identifiers immediately following the opening backticks (like 'python' or 'py') are removed.\n",
    "\n",
    "    Args:\n",
    "        code (str): The string containing Python code.\n",
    "\n",
    "    Returns:\n",
    "        str: The sanitized Python code.\n",
    "    \"\"\"\n",
    "    # Check if the string starts and ends with triple backticks\n",
    "    if code.startswith(\"```\") and code.endswith(\"```\"):\n",
    "        # Remove the triple backticks from the start and end of the string\n",
    "        code = code[3:-3]\n",
    "        \n",
    "    # Further check if the string starts with \"python\" or \"py\", which is common in markdown code blocks\n",
    "    if code.lstrip().startswith((\"python\", \"py\")):\n",
    "        # Find the first newline character and remove everything before it\n",
    "        code = code[code.find('\\n')+1:]\n",
    "\n",
    "    return code\n",
    "\n",
    "def write_to_py_file(folder: str, file_name: str, file_contents: str):\n",
    "    # Save function to .py file\n",
    "    file_contents = sanitize_python_code(file_contents)\n",
    "    with open(f\"{folder}/{file_name}.py\", \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "\n",
    "def write_description_to_json_file(folder: str, func: Callable):\n",
    "    # Save JSON representation to .json file\n",
    "    with open(f\"{folder}/{func.__name__}.json\", \"w\") as f:\n",
    "        json.dump(get_json_representation(func), f)\n",
    "        \n",
    "def write_generated_func_to_file(folder: str, func_name: str, generated_file_contents: str):\n",
    "    write_to_py_file(folder, func_name, generated_file_contents)\n",
    "    func = load_function_from_file(folder, func_name)\n",
    "    write_description_to_json_file(folder, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4f3c202-f5b0-40de-b752-8f45e6bbf6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject at 0x1e18d3d12b0> JSON: {\n",
       "  \"role\": \"assistant\",\n",
       "  \"content\": null,\n",
       "  \"function_call\": {\n",
       "    \"name\": \"make_new_function\",\n",
       "    \"arguments\": \"{\\n  \\\"function_name\\\": \\\"multiply_numbers\\\",\\n  \\\"arg_descriptions\\\": \\\"a list of numbers\\\",\\n  \\\"description\\\": \\\"Multiply together all the numbers in the given list\\\"\\n}\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = response_requesting_new_func['choices'][0]['message']\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7875ae65-b3ee-48a8-8261-b353a89a68f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new function request: {\n",
      "  \"function_name\": \"multiply_numbers\",\n",
      "  \"arg_descriptions\": \"a list of numbers\",\n",
      "  \"description\": \"Multiply together all the numbers in the given list\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "new_func_arguments_description = message['function_call'].get('arguments')\n",
    "print(f'new function request: {new_func_arguments_description}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7307329-e700-41e6-8fb4-c97063b11cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_new_function output:\n",
      "```python\n",
      "from typing import List\n",
      "\n",
      "def multiply_numbers(numbers: List[float]) -> float:\n",
      "    \"\"\"\n",
      "    Multiply together all the numbers in the given list.\n",
      "\n",
      "    Args:\n",
      "        numbers: A list of numbers.\n",
      "\n",
      "    Returns:\n",
      "        The product of all the numbers in the list.\n",
      "    \"\"\"\n",
      "    product = 1\n",
      "    for num in numbers:\n",
      "        product *= num\n",
      "    return product\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "new_file_contents = make_new_function(\n",
    "    **json.loads(new_func_arguments_description),\n",
    ")\n",
    "print(f'make_new_function output:\\n{new_file_contents}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a40a42ba-a2f6-4580-86b8-3753262f6bec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funcion written to file\n"
     ]
    }
   ],
   "source": [
    "new_func_name = json.loads(message['function_call']['arguments']).get('function_name')\n",
    "write_generated_func_to_file(FUNCTIONS_FOLDER, new_func_name, new_file_contents)\n",
    "print(f'Funcion written to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "98772709-a989-481e-9136-2a049b5d3e96",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'multiply_list': {'name': 'multiply_list',\n",
       "  'description': 'Multiply a list of numbers together and return the total value',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'numbers': {'type': 'array', 'items': {'type': 'number'}}},\n",
       "   'required': ['numbers']},\n",
       "  'returns': {'type': 'number',\n",
       "   'description': 'The product of all the numbers in the list'}},\n",
       " 'multiply_numbers': {'name': 'multiply_numbers',\n",
       "  'description': 'Multiply together all the numbers in the given list',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'numbers': {'type': 'array', 'items': {'type': 'number'}}},\n",
       "   'required': ['numbers']},\n",
       "  'return': {'type': 'number',\n",
       "   'description': 'The product of all the numbers in the list'}},\n",
       " 'test_func': {'name': 'test_func',\n",
       "  'description': \"Calculates the sine of the product of a and b and adds it to the dictionary d with the key 'new_val'.\",\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'d': {'type': 'object',\n",
       "     'description': 'A dictionary to which the new value will be added.'},\n",
       "    'a': {'type': 'integer', 'description': 'An integer value.'},\n",
       "    'b': {'type': 'number', 'description': 'A float value.'}},\n",
       "   'required': ['d', 'a', 'b']},\n",
       "  'return': {'type': 'string',\n",
       "   'description': 'A JSON string representation of the updated dictionary d.'}},\n",
       " 'test_func2': {'name': 'test_func2',\n",
       "  'description': 'Multiplies two float values and returns the result',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'a': {'type': 'number', 'description': 'A float value'},\n",
       "    'b': {'type': 'number', 'description': 'A float value'}},\n",
       "   'required': ['a', 'b']}}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func_descriptions = load_json_descriptions(FUNCTIONS_FOLDER)\n",
    "func_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cef8e73a-2dd8-4464-980f-5d69b6b88413",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next response from Chat model:\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": null,\n",
      "  \"function_call\": {\n",
      "    \"name\": \"multiply_list\",\n",
      "    \"arguments\": \"{\\n  \\\"numbers\\\": [3, 2, 6, 3, 6, 5, 4, 3, 6]\\n}\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response_using_new_func = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\", \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_GENERAL},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "        # message,\n",
    "        # {\n",
    "        #     \"role\": \"function\",\n",
    "        #     \"name\": called_function,\n",
    "        #     \"content\": function_response,\n",
    "        # },\n",
    "    ],\n",
    "    functions=[\n",
    "        make_new_function_description,\n",
    "        *func_descriptions.values(),\n",
    "    ],\n",
    "    function_call='auto',\n",
    ")\n",
    "print(f\"Next response from Chat model:\\n{response_using_new_func['choices'][0]['message']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d0d409-e518-41a1-99e9-ab757f5d8883",
   "metadata": {},
   "source": [
    "**NOTE:** We don't want to follow the standard format here of telling GPT what the function returned, we just want to pretend that we are again answering the original question, only now we have the new function available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9990744e-6173-47f1-9dd1-95d6d801cc58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function output:\n",
      "233280.0\n"
     ]
    }
   ],
   "source": [
    "# Extract the returned message\n",
    "message_using_func = response_using_new_func['choices'][0]['message']\n",
    "\n",
    "# From that message, get the name of the function called\n",
    "function_name = message_using_func[\"function_call\"][\"name\"]\n",
    "\n",
    "# Also get the arguments (this is a string representation of a JSON dict of arguments)\n",
    "arguments = message_using_func['function_call'].get('arguments')\n",
    "\n",
    "# Make the call to the function with the arguments that the LLM decided\n",
    "requested_func = load_function_from_file(FUNCTIONS_FOLDER, function_name)\n",
    "function_response = requested_func(\n",
    "    **json.loads(arguments),  # Unpack the arguments as keyword: value pairs\n",
    ")\n",
    "\n",
    "# Look at what the function returned\n",
    "print(f'Function output:\\n{function_response}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4527c-f796-4b4c-b20f-bebcd8cc5994",
   "metadata": {},
   "source": [
    "And then, pass that result back to the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8d3b3422-d4be-4fe6-a2d5-bf8d719a534c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-7S7yKGolOs1u6kTazgiqcBvpStmo1 at 0x1e18ccffd10> JSON: {\n",
       "  \"id\": \"chatcmpl-7S7yKGolOs1u6kTazgiqcBvpStmo1\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"created\": 1686938184,\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"role\": \"assistant\",\n",
       "        \"content\": \"The result of multiplying together all of the numbers [3, 2, 6, 3, 6, 5, 4, 3, 6] is 233280.\"\n",
       "      },\n",
       "      \"finish_reason\": \"stop\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 197,\n",
       "    \"completion_tokens\": 41,\n",
       "    \"total_tokens\": 238\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_response_message = {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": str(function_response),\n",
    "        }\n",
    "\n",
    "final_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT_GENERAL},\n",
    "        {\"role\": \"user\", \"content\": user_request},\n",
    "        message_using_func,  # We'll keep this context, but don't need to include when it made the new func\n",
    "        function_response_message,  # And the result of that function call\n",
    "    ],\n",
    ")\n",
    "final_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "817f95f5-88ae-4377-884a-0b1894deb4cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result of multiplying together all of the numbers [3, 2, 6, 3, 6, 5, 4, 3, 6] is 233280.'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0715e65b-c403-410f-9201-2e9f5ac4c745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
