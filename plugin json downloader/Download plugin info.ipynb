{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98cf18e-18cd-4a76-86d0-bfdb84024295",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "91c53ca1-b792-449c-8021-b0f384d814f2",
   "metadata": {},
   "source": [
    "## Intial attempt to download information about the gpt plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "659674ec-6b52-47b3-919e-c03484a011a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import os\n",
    "# import requests\n",
    "\n",
    "\n",
    "# # List of URLs for the GPT plugins you are interested in.\n",
    "# # Replace these with the actual URLs of the plugins.\n",
    "# plugin_urls = ['wolframalpha.com', 'www.instacart.com', 'www.kayak.com', 'fiscalnote.com', 'www.klarna.com', 'www.joinmilo.com', 'zapier.com', 'www.opentable.com']\n",
    "\n",
    "# # Directory where the downloaded files will be stored\n",
    "# download_dir = './downloaded_files'\n",
    "\n",
    "# # Make sure the download directory exists\n",
    "# os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# for url in tqdm(plugin_urls):\n",
    "#     if not url.startswith(\"https://\"):\n",
    "#         url = \"https://\"+url\n",
    "#     # Construct the URL for the ai-plugin.json file\n",
    "#     # file_url = os.path.join(url, '.well-known', 'ai-plugin.json')\n",
    "#     file_url = '/'.join([url, '.well-known', 'ai-plugin.json'])\n",
    "\n",
    "#     # Make a GET request to the file URL\n",
    "#     response = requests.get(file_url)\n",
    "\n",
    "#     # If the request was successful\n",
    "#     if response.status_code == 200:\n",
    "#         # Construct the path where the file will be saved\n",
    "#         file_path = os.path.join(download_dir, f'{url.replace(\"https://\", \"\")}_ai-plugin.json')\n",
    "\n",
    "#         # Write the content of the response to a file\n",
    "#         with open(file_path, 'wb') as file:\n",
    "#             file.write(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd439165-e24f-4343-9189-80824306a60f",
   "metadata": {},
   "source": [
    "## Including downloading the information found at the api.url in the ai-plugin.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f8c3b72-b7b8-483b-9423-0d1d9d9bddf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a098cbb1c59b4c668a81ef7d3f00ac92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on www.wolframalpha.com\n",
      "Found ai-plugin.json\n",
      "Working on www.instacart.com\n",
      "Working on www.kayak.com\n",
      "Working on fiscalnote.com\n",
      "Working on www.klarna.com\n",
      "Found ai-plugin.json\n",
      "Working on www.joinmilo.com\n",
      "Found ai-plugin.json\n",
      "Working on zapier.com\n",
      "Found ai-plugin.json\n"
     ]
    }
   ],
   "source": [
    "# from tqdm.auto import tqdm\n",
    "# import os\n",
    "# import json\n",
    "# import requests\n",
    "# import shutil\n",
    "# import re\n",
    "\n",
    "# websites = [\n",
    "#     \"www.wolframalpha.com\",\n",
    "#     \"www.instacart.com\",\n",
    "#     \"www.kayak.com\",\n",
    "#     \"fiscalnote.com\",\n",
    "#     \"www.klarna.com\",\n",
    "#     \"www.joinmilo.com\",\n",
    "#     \"zapier.com\",\n",
    "# ]\n",
    "\n",
    "# # Create the parent directory\n",
    "# if not os.path.exists(\"ai-plugins\"):\n",
    "#     os.makedirs(\"ai-plugins\")\n",
    "\n",
    "# for site in tqdm(websites):\n",
    "#     print(f'Working on {site}')\n",
    "    \n",
    "#     # Create a subfolder for each site\n",
    "#     subfolder_path = f\"ai-plugins/{site}\"\n",
    "#     if os.path.exists(subfolder_path):\n",
    "#         shutil.rmtree(subfolder_path)\n",
    "#     os.makedirs(subfolder_path)\n",
    "    \n",
    "#     # Fetch the ai-plugin.json\n",
    "#     url = f\"https://{site}/.well-known/ai-plugin.json\"\n",
    "#     response = requests.get(url)\n",
    "#     if response.status_code == 200:\n",
    "#         print(f'Found ai-plugin.json')\n",
    "#         plugin_json = response.json()\n",
    "\n",
    "#         # Save the ai-plugin.json to the respective subfolder\n",
    "#         with open(f\"{subfolder_path}/ai-plugin.json\", \"w\") as file:\n",
    "#             json.dump(plugin_json, file, indent=4)\n",
    "        \n",
    "#         # Create a new file for the endpoint pointed by api.url\n",
    "#         api_url = plugin_json.get(\"api\", {}).get(\"url\")\n",
    "#         if api_url:\n",
    "#             # Taking the last part of the URL\n",
    "#             last_segment = api_url.split('/')[-1]\n",
    "\n",
    "#             # Sanitizing the last segment to create a valid filename\n",
    "#             sanitized_filename = re.sub(r'[^a-zA-Z0-9\\-]', '_', last_segment)\n",
    "#             with open(f\"{subfolder_path}/{sanitized_url}\", \"w\") as file:\n",
    "#                 file.write(f\"This file represents the endpoint: {api_url}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d0c204-a917-4b4e-8b30-d711d49e9859",
   "metadata": {},
   "source": [
    "## Tidying up that code so that it is easier to improve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b122ec0-3d00-46fb-9077-95b1ae5e3323",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eefa06bf7f24c8d92efd65dffb4b7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "def clear_existing_directory(path: str) -> None:\n",
    "    \"\"\"Clears the existing directory if it exists\"\"\"\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "def fetch_plugin_json(site: str) -> dict:\n",
    "    \"\"\"Fetches the ai-plugin.json file from the site\"\"\"\n",
    "    url = f\"https://{site}/.well-known/ai-plugin.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "def save_json_to_file(json_obj: dict, filepath: str) -> None:\n",
    "    \"\"\"Saves a JSON object to a file\"\"\"\n",
    "    with open(filepath, \"w\") as file:\n",
    "        json.dump(json_obj, file, indent=4)\n",
    "\n",
    "def fetch_api_data(api_url: str) -> str:\n",
    "    \"\"\"Fetches data from the API endpoint\"\"\"\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    return None\n",
    "\n",
    "def create_api_endpoint_file(api_url: str, filepath: str) -> None:\n",
    "    \"\"\"Creates a new file with the data from the endpoint pointed by api.url\"\"\"\n",
    "    api_data = fetch_api_data(api_url)\n",
    "    if api_data:\n",
    "        with open(filepath, \"w\") as file:\n",
    "            file.write(api_data)\n",
    "\n",
    "def fetch_and_save_plugin(site: str, parent_dir: str) -> None:\n",
    "    \"\"\"Fetches the ai-plugin.json from a site and saves it to a subfolder\"\"\"\n",
    "    plugin_json = fetch_plugin_json(site)\n",
    "    if plugin_json:\n",
    "        subfolder_path = os.path.join(parent_dir, site)\n",
    "        os.makedirs(subfolder_path)\n",
    "        save_json_to_file(plugin_json, os.path.join(subfolder_path, \"ai-plugin.json\"))\n",
    "        api_url = plugin_json.get(\"api\", {}).get(\"url\")\n",
    "        if api_url:\n",
    "            last_segment = api_url.split('/')[-1]\n",
    "            sanitized_filename = re.sub(r'[^a-zA-Z0-9\\-\\.]', '_', last_segment)\n",
    "            if sanitized_filename == \"\":\n",
    "                sanitized_filename = \"default_api_endpoint\"\n",
    "            create_api_endpoint_file(api_url, os.path.join(subfolder_path, sanitized_filename))\n",
    "\n",
    "\n",
    "def update_plugins_info(websites):\n",
    "    # Delete the ai-plugins directory if it already exists and create a new one\n",
    "    clear_existing_directory(\"ai-plugins\")\n",
    "\n",
    "    # Use a ThreadPoolExecutor to fetch and save plugins from all websites simultaneously\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(fetch_and_save_plugin, websites, [\"ai-plugins\"]*len(websites)), total=len(websites)))\n",
    "    \n",
    "\n",
    "websites = [\n",
    "    \"www.wolframalpha.com\",\n",
    "    \"www.instacart.com\",\n",
    "    \"www.kayak.com\",\n",
    "    \"fiscalnote.com\",\n",
    "    \"www.klarna.com\",\n",
    "    \"www.joinmilo.com\",\n",
    "    \"zapier.com\",\n",
    "]\n",
    "\n",
    "update_plugins_info(websites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2004c248-3fb9-4025-8d7c-8fcbe7e430d9",
   "metadata": {},
   "source": [
    "## Further improvements:\n",
    "\n",
    "\n",
    "Updates:\n",
    "- I no longer want to delete the whole ai-plugins folder initially, from now on I only want to update what is already in there.\n",
    "- If the content of the already saved files is exactly the same as what is obtained from the URLs, then no update needs to happen (the files do not need to be written again).\n",
    "- If the content of the already saved files differs, then the existing files should be copied into a subfolder that includes the current date and time in the folder name (i.e. keep a record of the obsolete files) and then the up-to-date files should be overwritten with the new content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be5963d3-402c-4108-ac49-afe3d9574a15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91344bd5f437427f88d6016484211be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New ai-plugin.json detected for showme.redstarplugin.com\n",
      "New api data detected for www.wolframalpha.com\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import shutil\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "def clear_existing_directory(path: str) -> None:\n",
    "    \"\"\"Clears the existing directory if it exists\n",
    "    \n",
    "    Note: Useful for testing to start from a clean slate. Not used otherwise\n",
    "    \"\"\"\n",
    "    if os.path.exists(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path)\n",
    "\n",
    "def fetch_plugin_json(site: str) -> dict:\n",
    "    \"\"\"Fetches the ai-plugin.json file from the site\"\"\"\n",
    "    url = f\"https://{site}/.well-known/ai-plugin.json\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    return None\n",
    "\n",
    "def save_json_to_file(json_obj: dict, filepath: str) -> None:\n",
    "    \"\"\"Saves a JSON object to a file\"\"\"\n",
    "    with open(filepath, \"w\") as file:\n",
    "        json.dump(json_obj, file, indent=4)\n",
    "\n",
    "def fetch_api_data(api_url: str) -> str:\n",
    "    \"\"\"Fetches data from the API endpoint\"\"\"\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.text\n",
    "    return None\n",
    "\n",
    "def create_api_endpoint_file(api_url: str, filepath: str) -> None:\n",
    "    \"\"\"Creates a new file with the data from the endpoint pointed by api.url\"\"\"\n",
    "    api_data = fetch_api_data(api_url)\n",
    "    if api_data:\n",
    "        with open(filepath, \"w\") as file:\n",
    "            file.write(api_data)\n",
    "\n",
    "def read_json_from_file(filepath: str) -> dict:\n",
    "    \"\"\"Reads a JSON object from a file\"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def get_existing_file_content(filepath: str) -> str:\n",
    "    \"\"\"Returns the content of the file if it exists, otherwise returns None.\"\"\"\n",
    "    if os.path.exists(filepath):\n",
    "        with open(filepath, \"r\") as file:\n",
    "            return file.read()\n",
    "    return None\n",
    "\n",
    "def save_old_file(filepath: str, old_files_subfolder: str) -> None:\n",
    "    \"\"\"Saves the old file in a subfolder with the current date and time.\"\"\"\n",
    "    shutil.copy(filepath, old_files_subfolder)\n",
    "\n",
    "def create_old_files_subfolder(parent_dir: str) -> str:\n",
    "    \"\"\"Creates a subfolder for old files with the current date and time.\"\"\"\n",
    "    old_files_subfolder = os.path.join(parent_dir, datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "    os.makedirs(old_files_subfolder, exist_ok=True)\n",
    "    return old_files_subfolder\n",
    "\n",
    "def fetch_and_save_plugin(site: str, parent_dir: str) -> None:\n",
    "    \"\"\"Fetches the ai-plugin.json from a site and saves it to a subfolder\"\"\"\n",
    "    plugin_json = fetch_plugin_json(site)\n",
    "    if plugin_json:\n",
    "        subfolder_path = os.path.join(parent_dir, site)\n",
    "        os.makedirs(subfolder_path, exist_ok=True)\n",
    "\n",
    "        # Handle ai-plugin.json\n",
    "        plugin_json_filepath = os.path.join(subfolder_path, \"ai-plugin.json\")\n",
    "        existing_plugin_json = get_existing_file_content(plugin_json_filepath)\n",
    "        new_plugin_json = json.dumps(plugin_json, indent=4)\n",
    "\n",
    "        # Handle API endpoint\n",
    "        api_url = plugin_json.get(\"api\", {}).get(\"url\")\n",
    "        last_segment = api_url.split('/')[-1]\n",
    "        sanitized_filename = re.sub(r'[^a-zA-Z0-9\\-\\.]', '_', last_segment)\n",
    "        if sanitized_filename == \"\":\n",
    "            sanitized_filename = \"default_api_endpoint\"\n",
    "        api_filepath = os.path.join(subfolder_path, sanitized_filename)\n",
    "        existing_api_data = get_existing_file_content(api_filepath)\n",
    "        new_api_data = fetch_api_data(api_url)\n",
    "\n",
    "        # Check if either file changed\n",
    "        plugin_json_updated = False\n",
    "        api_info_updated = False\n",
    "        if not existing_plugin_json or json.loads(existing_plugin_json) != json.loads(new_plugin_json):\n",
    "            print(f'New ai-plugin.json detected for {site}')\n",
    "            plugin_json_updated = True\n",
    "        if existing_api_data != new_api_data:\n",
    "            print(f'New api data detected for {site}')\n",
    "            api_info_updated = True\n",
    "            \n",
    "        # If either file has changed, create a subfolder for old files and save both old files to it\n",
    "        if plugin_json_updated or api_info_updated:\n",
    "            old_files_subfolder = create_old_files_subfolder(subfolder_path)\n",
    "            if os.path.exists(plugin_json_filepath):\n",
    "                save_old_file(plugin_json_filepath, old_files_subfolder)\n",
    "            if os.path.exists(api_filepath):\n",
    "                save_old_file(api_filepath, old_files_subfolder)\n",
    "\n",
    "        # Save new data\n",
    "        if plugin_json_updated:\n",
    "            save_json_to_file(plugin_json, plugin_json_filepath)\n",
    "        if api_info_updated:\n",
    "            create_api_endpoint_file(api_url, api_filepath)\n",
    "\n",
    "def update_plugins_info(websites):\n",
    "    # Create the ai-plugins directory if it does not exist\n",
    "    if not os.path.exists(\"ai-plugins\"):\n",
    "        os.makedirs(\"ai-plugins\")\n",
    "\n",
    "    # # Use a ThreadPoolExecutor to fetch and save plugins from all websites simultaneously\n",
    "    # with ThreadPoolExecutor() as executor:\n",
    "    #     list(tqdm(executor.map(fetch_and_save_plugin, websites, [\"ai-plugins\"]*len(websites)), total=len(websites)))\n",
    "    \n",
    "    for site in tqdm(websites):\n",
    "        fetch_and_save_plugin(site, \"ai-plugins\")\n",
    "    \n",
    "\n",
    "websites = [\n",
    "    \"showme.redstarplugin.com\",\n",
    "    \"www.wolframalpha.com\",\n",
    "    \"www.instacart.com\",\n",
    "    \"www.kayak.com\",\n",
    "    \"fiscalnote.com\",\n",
    "    \"www.klarna.com\",\n",
    "    \"www.joinmilo.com\",\n",
    "    \"zapier.com\",\n",
    "]\n",
    "\n",
    "update_plugins_info(websites)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdfd79f-a282-4f2f-8c5c-f8bc5b31ecf9",
   "metadata": {},
   "source": [
    "#  TODO:\n",
    "- Why is wolfram apispec.json being detected as changed when it isn't\n",
    "- I can json.loads, but what if it's a toml instead? \n",
    "- hmm...\n",
    "- Add more plugin addresses! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "074f2d80-ee94-47e7-bb70-89344102f54c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing = get_existing_file_content('ai-plugins/www.wolframalpha.com/apispec.json')\n",
    "new = fetch_api_data('https://www.wolframalpha.com/.well-known/apispec.json')\n",
    "json.loads(existing) == json.loads(new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
