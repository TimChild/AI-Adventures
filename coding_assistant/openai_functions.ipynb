{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85877cc8-c921-4272-9185-982790b66573",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "with open(\"../API_KEY\", \"r\") as f:\n",
    "    key = f.read()\n",
    "\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6151b859-1254-4c90-821b-9920333f7b6c",
   "metadata": {},
   "source": [
    "# General Plan:\n",
    "- Make a function that converts a python function into the json representation required by openai\n",
    "- Then allow for making a chain where GPT mostly creates functions for itself:\n",
    "    - Get gpt to make a function\n",
    "    - Get gpt to save that function in a folder along with the json representation of the function\n",
    "    - Automatically include all tools in the folder (i.e. using the json representations, but then being able to call the functions)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467915c2-2f2f-46de-82f6-4d79186a4c64",
   "metadata": {},
   "source": [
    "## First, let's test out the function calling\n",
    "\n",
    "Make a very basic function first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff546f2b-c239-4fc6-a671-cb64318b36c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_weather_report(day_of_week: int, weather_type: str, temperature: float = 10.0) -> str:\n",
    "    \"\"\"\n",
    "    Converts information about weather into a string representation.\n",
    "\n",
    "    Args:\n",
    "        day_of_week (int): The day of the week from 0 to 6.\n",
    "        weather_type (str): The type of weather, can be \"sunny\", \"rainy\", or \"windy\".\n",
    "        temperature (float, optional): Temperature in Celsius. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the weather report.\n",
    "    \"\"\"\n",
    "    return f'For the {day_of_week}th day of the week, the weather is predicted to be {weather_type} with a max temperature of {temperature}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfb21af-2b1b-4a46-a5da-28dea03461fa",
   "metadata": {},
   "source": [
    "Manually create the JSON representation for that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442b754f-cae4-457c-b242-70eddc884fb8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "weather_report_function = {\n",
    "    \"name\": \"get_weather_report\",\n",
    "    \"description\": \"Converts information about weather into a string representation\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"day_of_week\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The day of the week from 0 to 6\",\n",
    "            },\n",
    "            \"weather_type\": {\"type\": \"string\", \"enum\": [\"sunny\", \"rainy\", \"windy\"]},\n",
    "            \"temperature\": {\"type\": \"number\", \"description\": \"Temperature in Celsius. Defaults to 10.0.\"},\n",
    "        },\n",
    "        \"required\": [\"day_of_week\", \"weather_type\"],\n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88734a8-341d-4b2f-93d9-19f2d71b3465",
   "metadata": {},
   "source": [
    "Check that openai uses the function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fa2a9d-42f6-4f25-8d66-4c9c3a8fb2e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"It's currently a sunny 36.4C this Tuesday, can you give me a weather report?\"}],\n",
    "    functions=[\n",
    "        weather_report_function,\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c2ef1-5e4c-4891-97dc-cb0b0929054e",
   "metadata": {},
   "source": [
    "Then use the result of the function call to generate the next response in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db937845-36ea-4236-bc7d-30c5fd6e7d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message = response['choices'][0]['message']\n",
    "if message.get(\"function_call\"):\n",
    "    print(f'Chat model responded with a function call:\\n{message.get(\"function_call\")}')\n",
    "    print(f'\\nNow determining next output including function return')\n",
    "    function_name = message[\"function_call\"][\"name\"]\n",
    "\n",
    "    # Step 3, call the function\n",
    "    # Note: the JSON response from the model may not be valid JSON\n",
    "    function_response = get_weather_report(\n",
    "        **json.loads(message['function_call'].get('arguments')),\n",
    "    )\n",
    "    print(f'Function output:\\n{function_response}')\n",
    "\n",
    "    # Step 4, send model the info on the function call and function response\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"It's currently 36.4C this Tuesday, can you give me a weather report?\"},\n",
    "            message,\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    print(f\"Next response from Chat model:\\n{second_response['choices'][0]['message']}\")\n",
    "elif message.get('content'):\n",
    "    print(f'Chat model responded directly with:\\n{message.get(\"content\")}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7145eaea-3302-4517-86f1-f7c8eef10d41",
   "metadata": {},
   "source": [
    "## Basic test worked, now let's start automating\n",
    "\n",
    "Below is a function that should convert a given function into the json representation of that function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ae65f-617f-45a2-8c62-aadbcf0e3b5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "import numpy\n",
    "from typing import Callable\n",
    "\n",
    "# def get_json_representation(func: Callable) -> dict:\n",
    "#     \"\"\"\n",
    "#     Returns a JSON representation of the given function.\n",
    "\n",
    "#     Args:\n",
    "#         func (Callable): The function to represent.\n",
    "\n",
    "#     Returns:\n",
    "#         str: The JSON representation of the function.\n",
    "#     \"\"\"\n",
    "#     signature = inspect.signature(func)\n",
    "#     docstring = inspect.getdoc(func)\n",
    "\n",
    "#     # Parse the docstring\n",
    "#     docstring_lines = docstring.split('\\n')\n",
    "#     description = docstring_lines[0]\n",
    "#     parameter_descriptions = {}\n",
    "#     args_index = -1\n",
    "#     for line in docstring_lines[1:]:\n",
    "#         if line.strip().startswith(\"Args:\"):\n",
    "#             args_index = docstring_lines.index(line)\n",
    "#             break\n",
    "#     if args_index != -1:\n",
    "#         for line in docstring_lines[args_index+1:]:\n",
    "#             if line.strip().startswith(tuple([f\"{param}\" for param in signature.parameters.keys()])):\n",
    "#                 param, desc = line.strip().split(\":\", 1)\n",
    "#                 param = param.split(\" (\")[0]  # Remove type hinting if present\n",
    "#                 parameter_descriptions[param] = desc.strip()\n",
    "\n",
    "#     # Map Python types to JSON types\n",
    "#     type_mapping = {str: 'string', bool: 'boolean'}\n",
    "\n",
    "#     # Build the JSON representation\n",
    "#     json_representation = {\n",
    "#         'name': func.__name__,\n",
    "#         'description': description,\n",
    "#         'parameters': {\n",
    "#             'type': 'object',\n",
    "#             'properties': {\n",
    "#                 name: {\n",
    "#                     'type': type_mapping.get(param.annotation, 'any') if not numpy.issubdtype(param.annotation, numpy.number) else 'number',\n",
    "#                     'description': parameter_descriptions.get(name, '')\n",
    "#                 }\n",
    "#                 for name, param in signature.parameters.items()\n",
    "#             },\n",
    "#             'required': [name for name, param in signature.parameters.items() if param.default is param.empty]\n",
    "#         }\n",
    "#     }\n",
    "\n",
    "#     return json_representation\n",
    "\n",
    "def get_json_representation(func: Callable) -> dict:\n",
    "    \"\"\"\n",
    "    Uses the openai.ChatCompletion.create endpoint to return the necessary imports for a function supplied as a string.\n",
    "\n",
    "    Args:\n",
    "        function_str (str): The function for which to get the necessary imports, supplied as a string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string of the necessary imports for the function.\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'model': 'gpt-3.5-turbo-0613',\n",
    "        'temperature': 0.0,\n",
    "        'messages': [\n",
    "            {\"role\": \"system\", \"content\": '''Your job is to convert a python function into a json representation with a specific form.\n",
    "For example, given this function:\n",
    "```\n",
    "\n",
    "def get_weather_report(day_of_week: int, weather_type: str, temperature: float = 10.0) -> str:\n",
    "    \"\"\"\n",
    "    Converts information about weather into a string representation.\n",
    "\n",
    "    Args:\n",
    "        day_of_week (int): The day of the week from 0 to 6.\n",
    "        weather_type (str): The type of weather, can be \"sunny\", \"rainy\", or \"windy\".\n",
    "        temperature (float, optional): Temperature in Celsius. Defaults to 10.0.\n",
    "\n",
    "    Returns:\n",
    "        str: A string representation of the weather report.\n",
    "    \"\"\"\n",
    "    return f'For the {day_of_week}th day of the week, the weather is predicted to be {weather_type} with a max temperature of {temperature}'\n",
    "```\n",
    "\n",
    "You should return:\n",
    "```\n",
    "{\n",
    "    \"name\": \"get_weather_report\",\n",
    "    \"description\": \"Converts information about weather into a string representation\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"day_of_week\": {\n",
    "                \"type\": \"number\",\n",
    "                \"description\": \"The day of the week from 0 to 6\",\n",
    "            },\n",
    "            \"weather_type\": {\"type\": \"string\", \"enum\": [\"sunny\", \"rainy\", \"windy\"]},\n",
    "            \"temperature\": {\"type\": \"number\", \"description\": \"Temperature in Celsius. Defaults to 10.0.\"},\n",
    "        },\n",
    "        \"required\": [\"day_of_week\", \"weather_type\"],\n",
    "    },\n",
    "}\n",
    "```\n",
    "Return the JSON ONLY.'''},\n",
    "            {\"role\": \"user\", \"content\": inspect.getsource(func)}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = openai.ChatCompletion.create(**parameters)\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    assistant_response = response['choices'][0]['message']['content']\n",
    "\n",
    "    return json.loads(assistant_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72231f9-866a-4534-a31a-e3f2878a13e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "json_rep = get_json_representation(get_weather_report)\n",
    "print(json.dumps(json_rep, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d454d-8bea-4f6f-9f2b-2269178dc441",
   "metadata": {},
   "source": [
    "---\n",
    "That seems to work reasonably well, so now let's make sure we get the same responses from the LLM using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ce347-29ab-49ba-8e71-1dfcc904ee19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"It's currently a sunny 36.4C this Tuesday, can you give me a weather report?\"}],\n",
    "    functions=[\n",
    "        get_json_representation(get_weather_report),\n",
    "    ],\n",
    "    function_call=\"auto\",\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62674207-65b6-4a81-b048-1e47afb0fa80",
   "metadata": {},
   "source": [
    "Then use the result of the function call to generate the next response in the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457c8a31-4825-4e7d-abaa-d32c33a3964b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message = response['choices'][0]['message']\n",
    "if message.get(\"function_call\"):\n",
    "    print(f'Chat model responded with a function call:\\n{message.get(\"function_call\")}')\n",
    "    print(f'\\nNow determining next output including function return')\n",
    "    function_name = message[\"function_call\"][\"name\"]\n",
    "\n",
    "    # Step 3, call the function\n",
    "    # Note: the JSON response from the model may not be valid JSON\n",
    "    function_response = get_weather_report(\n",
    "        **json.loads(message['function_call'].get('arguments')),\n",
    "    )\n",
    "    print(f'Function output:\\n{function_response}')\n",
    "\n",
    "    # Step 4, send model the info on the function call and function response\n",
    "    second_response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"It's currently 36.4C this Tuesday, can you give me a weather report?\"},\n",
    "            message,\n",
    "            {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "            },\n",
    "        ],\n",
    "    )\n",
    "    print(f\"Next response from Chat model:\\n{second_response['choices'][0]['message']}\")\n",
    "elif message.get('content'):\n",
    "    print(f'Chat model responded directly with:\\n{message.get(\"content\")}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d275039-c4cb-47f0-80fa-f39a1d12ee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "functions_folder = 'functions'\n",
    "os.makedirs(functions_folder, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40439a-f94d-4c30-9d86-90a6c129b7b0",
   "metadata": {},
   "source": [
    "## Make a function that saves the func/description to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee3799-2edf-42ec-8577-1d304ae7d692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Callable\n",
    "\n",
    "def get_imports_for_function(function_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Uses the openai.ChatCompletion.create endpoint to return the necessary imports for a function supplied as a string.\n",
    "\n",
    "    Args:\n",
    "        function_str (str): The function for which to get the necessary imports, supplied as a string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string of the necessary imports for the function.\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'model': 'gpt-3.5-turbo-0613',\n",
    "        'messages': [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"Your job is to return ONLY the python imports that would be required to run the function given by the user. For example:\n",
    "            -----\n",
    "            The user has given you this function:\n",
    "            ```\n",
    "            def some_function(a, b, **kwargs):\n",
    "                c = np.sin(a+b)\n",
    "                result = {'input_a': a, 'input_b': b, 'res': c}\n",
    "                return json.dumps(result)\n",
    "            ```\n",
    "            You should return:\n",
    "            ```\n",
    "            import numpy as np\n",
    "            import json\n",
    "            ```\n",
    "            -----\n",
    "            \n",
    "            Do not include ANY other text other than the imports required. If no imports are required return \"No imports required\".\n",
    "            \"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"I have a function: {function_str}. What are the necessary imports for this function?\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = openai.ChatCompletion.create(**parameters)\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    assistant_response = response['choices'][0]['message']['content']\n",
    "\n",
    "    return assistant_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ae48b-475e-4330-8e45-43cdb452d5aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json \n",
    "\n",
    "def test_func(d: dict, a: int, b: float) -> str:\n",
    "    \"\"\"\n",
    "    Calculates the sine of the product of a and b and adds it to the dictionary d with the key 'new_val'.\n",
    "\n",
    "    Args:\n",
    "      d: A dictionary to which the new value will be added.\n",
    "      a: An integer value.\n",
    "      b: A float value.\n",
    "\n",
    "    Returns:\n",
    "      A JSON string representation of the updated dictionary d.\n",
    "    \"\"\"\n",
    "    d['new_val'] = np.sin(a*b)\n",
    "    return json.dumps(d)\n",
    "\n",
    "test_func({}, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9432110-2855-403d-a25a-133af33be9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_imports_for_function(inspect.getsource(test_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2febe3f6-9ace-4de9-a16b-2d1d4fac1e72",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_func2(a: float, b: float) -> float:\n",
    "    \"\"\"\n",
    "    Multiplies two float values and returns the result.\n",
    "\n",
    "    Args:\n",
    "      a: A float value.\n",
    "      b: A float value.\n",
    "\n",
    "    Returns:\n",
    "      The product of a and b.\n",
    "    \"\"\"\n",
    "    return a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae005f2-6234-4ef9-9012-f412e3a466f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "get_imports_for_function(inspect.getsource(test_func2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66800cb9-bafa-4a3e-aed3-2b26d2ac0738",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_func_and_json(func: Callable, func_folder: str) -> None:\n",
    "    \"\"\"\n",
    "    Saves the given function and its JSON representation to a subfolder of func_folder.\n",
    "\n",
    "    Args:\n",
    "        func (Callable): The function to save.\n",
    "        func_folder (str): The path to the folder where the function and JSON representation will be saved.\n",
    "    \"\"\"\n",
    "    # Get the imports required for the function\n",
    "    imports_string = get_imports_for_function(inspect.getsource(func))\n",
    "    if 'no imports required' in imports_string.lower():\n",
    "        imports_string = ''\n",
    "    else:\n",
    "        imports_string += '\\n\\n\\n'\n",
    "        \n",
    "    file_contents = imports_string+inspect.getsource(func)\n",
    "    \n",
    "    # Save function to .py file\n",
    "    with open(f\"{func_folder}/{func.__name__}.py\", \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "\n",
    "    # Save JSON representation to .json file\n",
    "    with open(f\"{func_folder}/{func.__name__}.json\", \"w\") as f:\n",
    "        json.dump(get_json_representation(func), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c3851c-6549-4b20-8cee-9ca5abca1dc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_func_and_json(test_func, func_folder=functions_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f9a92d-e8f7-4153-a5be-9d335c7a4aff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_func_and_json(test_func2, func_folder=functions_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3128a-650b-4550-b6ca-f21fb20728e6",
   "metadata": {},
   "source": [
    "# TODOs:\n",
    "- Load all descriptions from folder to pass into completion\n",
    "- Run the functions in the files when completion requests function call\n",
    "- Tidy up into something nice\n",
    "- Integrate this with asking GPT to make a new function (and automatically save etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2116d3d-6f17-42d7-89d6-757079addf2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def load_json_files(directory: str) -> dict:\n",
    "    \"\"\"\n",
    "    Loads the contents of all the .json files in a directory.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory to load .json files from.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary where the key is the name of the json file (excluding the .json extension) and the value is the content of the .json file.\n",
    "    \"\"\"\n",
    "    json_data = {}\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file is a .json file\n",
    "        if filename.endswith(\".json\"):\n",
    "            # Remove the .json extension from the filename\n",
    "            name = filename[:-5]\n",
    "            # Open the .json file and load its contents\n",
    "            with open(os.path.join(directory, filename), 'r') as f:\n",
    "                data = json.load(f)\n",
    "            # Add the data to the dictionary\n",
    "            json_data[name] = data\n",
    "\n",
    "    return json_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d81fd7-cb33-4131-a3d8-5e98834b51fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function_descriptions = load_json_files('functions')\n",
    "function_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346c710-97b3-43ad-9c14-a4049b16dda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "\n",
    "def load_function_from_file(directory: str, filename: str):\n",
    "    \"\"\"\n",
    "    Loads a function from a .py file.\n",
    "\n",
    "    Args:\n",
    "        directory (str): The directory where the .py file is located.\n",
    "        filename (str): The name of the .py file (excluding the .py extension).\n",
    "\n",
    "    Returns:\n",
    "        function: The function contained in the .py file.\n",
    "    \"\"\"\n",
    "    # Create the path to the .py file\n",
    "    file_path = os.path.join(directory, filename + \".py\")\n",
    "\n",
    "    # Load the spec of the module\n",
    "    spec = importlib.util.spec_from_file_location(filename, file_path)\n",
    "\n",
    "    # Create a module from the spec\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "\n",
    "    # Execute the module to get the function\n",
    "    spec.loader.exec_module(module)\n",
    "\n",
    "    # Get the function from the module\n",
    "    function = getattr(module, filename)\n",
    "\n",
    "    return function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6687ca13-2da8-4ddf-9459-d739d2b5dc5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "funcs = {}\n",
    "for func_name in function_descriptions:\n",
    "    funcs[func_name] = load_function_from_file('functions', func_name)\n",
    "funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f09b9e-ea6b-498f-b71e-04e97e8e93c4",
   "metadata": {},
   "source": [
    "# Now let's provide a way for GPT to make it's own function, save it, and use it in its next response!\n",
    "\n",
    "- Make a write python code function (the function should just take a description of what the code needs to do so that a separate prompt can be used to actually generate the code)\n",
    "\n",
    "- Note: Maybe can improve the code generator by making it fill in a fake function that takes args for 'signature', 'docstring', 'code body' or something like that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf0077-c189-4209-a8b0-00e93351f659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e38a60-cf69-4bd0-8708-33cd9dd4d2f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_new_function(function_name: str, arg_descriptions: str, description: str):\n",
    "    \"\"\"\n",
    "    Use this to make a new function with given `function_name` that will then be accessible to use for future messages. The new function will be made to carry out the task described in the `description` given the arguments described by `arg_descriptions`\n",
    "    \n",
    "    Args:\n",
    "        function_name: Name to give the new function (should follow python naming conventions)\n",
    "        arg_descriptions: A description of any arguments that the function should take (including type, and default value if appropriate)\n",
    "        description: A description of what the function should do (including the what it should output)\n",
    "    \"\"\"\n",
    "    parameters = {\n",
    "        'model': 'gpt-3.5-turbo-0613',\n",
    "        'temperature': 0.0,\n",
    "        'messages': [\n",
    "            {\"role\": \"system\", \"content\": \"\"\"You are an expert python coder that will be tasked with generating the code to go in a .py file for a single function given some specific information from the user.\n",
    "You will be provided:\n",
    "    - function_name: The name to give the new function\n",
    "    - arg_descriptions: Descriptions of all the arguments the function should take (if their types are missing, try to infer them)\n",
    "    - description: What the function should do with the given arguments\n",
    "\n",
    "When generating the new function you should follow these rules:\n",
    "    - Include ONLY the text that will be in the python file (e.g. starting with `import ...` unless no imports are necessary in which case, starting with `def ...`)\n",
    "    - Do NOT include any plain text explanation at the end of the written code\n",
    "    - Use the latest python programming techniques and best practices\n",
    "    - Use the latest/best python libraries when appropriate (e.g. if plotting, use `plotly` instead of `matplotlib` because plotly is better library even though matplotlib is better known)\n",
    "    - Always include a google style docstring\n",
    "    - Include type hints for the inputs and output\n",
    "    - Include all necessary imports\n",
    "    - Do NOT use markdown backticks to surround your output, return ONLY the contents of the .py file\n",
    "\"\"\"},\n",
    "            {\"role\": \"user\", \"content\": f\"function_name: {function_name}\\narg_descriptions: {arg_descriptions}\\ndescription: {description}\"}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = openai.ChatCompletion.create(**parameters)\n",
    "\n",
    "    # Extract the assistant's response\n",
    "    function_code = response['choices'][0]['message']['content']\n",
    "    return function_code\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90212f12-a9ae-471f-a9ba-441d8cf559fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_new_function_json = get_json_representation(make_new_function)\n",
    "make_new_function_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5ed0ca-f69d-4b5c-915d-e8cb5084782f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I'd like you to multiply a list of numbers together and return the total value, the list is [3,2,6,3,6,5,4,3,6].\"}],\n",
    "    functions=[\n",
    "        make_new_function_json,\n",
    "    ],\n",
    "    # function_call=\"auto\",\n",
    "    function_call={\"name\": \"make_new_function\"},  # Force using the function\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11b16c0-b7f1-4e8d-98e5-1304bd24ca37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "def sanitize_python_code(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Sanitizes a string containing Python code. If the code is surrounded by markdown triple backticks, they are removed.\n",
    "    Also, language identifiers immediately following the opening backticks (like 'python' or 'py') are removed.\n",
    "\n",
    "    Args:\n",
    "        code (str): The string containing Python code.\n",
    "\n",
    "    Returns:\n",
    "        str: The sanitized Python code.\n",
    "    \"\"\"\n",
    "    # Check if the string starts and ends with triple backticks\n",
    "    if code.startswith(\"```\") and code.endswith(\"```\"):\n",
    "        # Remove the triple backticks from the start and end of the string\n",
    "        code = code[3:-3]\n",
    "        \n",
    "    # Further check if the string starts with \"python\" or \"py\", which is common in markdown code blocks\n",
    "    if code.lstrip().startswith((\"python\", \"py\")):\n",
    "        # Find the first newline character and remove everything before it\n",
    "        code = code[code.find('\\n')+1:]\n",
    "\n",
    "    return code\n",
    "\n",
    "def write_to_py_file(folder: str, file_name: str, file_contents: str):\n",
    "    # Save function to .py file\n",
    "    file_contents = sanitize_python_code(file_contents)\n",
    "    with open(f\"{folder}/{file_name}.py\", \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "\n",
    "def write_description_to_json_file(folder: str, func: Callable):\n",
    "    # Save JSON representation to .json file\n",
    "    with open(f\"{folder}/{func.__name__}.json\", \"w\") as f:\n",
    "        json.dump(get_json_representation(func), f)\n",
    "        \n",
    "def write_generated_func_to_file(folder: str, func_name: str, generated_file_contents: str):\n",
    "    write_to_py_file(folder, func_name, generated_file_contents)\n",
    "    func = load_function_from_file(folder, func_name)\n",
    "    write_description_to_json_file(folder, func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c16217-e957-4dc7-b5a1-6a7f3a8519c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(json.dumps(func_descriptions['multiply_list'], indent=4))\n",
    "print()\n",
    "print(json.dumps(func_descriptions['test_func'], indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb12495-3528-4ec9-b2e0-e34d0ffccf51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message = response['choices'][0]['message']\n",
    "\n",
    "print(f'Chat model responded with a function call:\\n{message.get(\"function_call\")}')\n",
    "print(f'\\nNow generating new function')\n",
    "called_function = message[\"function_call\"][\"name\"]\n",
    "\n",
    "# Step 3, call the function\n",
    "# Note: the JSON response from the model may not be valid JSON\n",
    "new_file_contents = make_new_function(\n",
    "    **json.loads(message['function_call'].get('arguments')),\n",
    ")\n",
    "print(f'Function output:\\n{new_file_contents}')\n",
    "\n",
    "new_func_name = json.loads(message['function_call']['arguments']).get('function_name')\n",
    "write_generated_func_to_file(functions_folder, new_func_name, new_file_contents)\n",
    "print(f'Funcion written to file')\n",
    "\n",
    "func_descriptions = load_json_files(functions_folder)\n",
    "print(f'Function description written to file')\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf3b636-2317-4c9b-8960-e54d1d02a39d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# func_descriptions['multiply_list']['parameters']['properties']['numbers']['type'] = 'object'\n",
    "# del func_descriptions['multiply_list']['parameters']['properties']['numbers']['items']\n",
    "# del func_descriptions['multiply_list']\n",
    "func_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d72fb60-60f9-47e5-ae24-3348538bab11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " \n",
    "# Step 4, send model the info on the function call and function response\n",
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\", \n",
    "    messages=[{\"role\": \"user\", \"content\": \"I'd like you to multiply a list of numbers together and return the total value, the list is [3,2,6,3,6,5,4,3,6].\"},\n",
    "        # message,\n",
    "        # {\n",
    "        #     \"role\": \"function\",\n",
    "        #     \"name\": called_function,\n",
    "        #     \"content\": function_response,\n",
    "        # },\n",
    "    ],\n",
    "    functions=[\n",
    "        make_new_function_json,\n",
    "        *func_descriptions.values(),\n",
    "    ]\n",
    ")\n",
    "print(f\"Next response from Chat model:\\n{second_response['choices'][0]['message']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a84e6d7-78fb-4d71-b6d5-eb7b098e3c53",
   "metadata": {},
   "source": [
    "**NOTE:** We don't want to follow the standard format here of telling GPT what the function returned, we just want to pretend that we are again answering the original question, only now we have the new function available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1555083d-e035-4b63-960b-beb100ca6b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "message = second_response.choices[0]['message']\n",
    "print(f'Chat model responded with a function call:\\n{message.get(\"function_call\")}')\n",
    "print(f'\\nNow determining next output including function return')\n",
    "function_name = message[\"function_call\"][\"name\"]\n",
    "\n",
    "# Step 3, call the function\n",
    "# Note: the JSON response from the model may not be valid JSON\n",
    "func = load_function_from_file(functions_folder, function_name)\n",
    "print(f'Using func: {func}')\n",
    "function_response = func(\n",
    "    **json.loads(message['function_call'].get('arguments')),\n",
    ")\n",
    "print(f'Function output:\\n{function_response}')\n",
    "\n",
    "# Step 4, send model the info on the function call and function response\n",
    "second_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"I'd like you to multiply a list of numbers together and return the total value, the list is [3,2,6,3,6,5,4,3,6].\"},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": str(function_response),\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(f\"Next response from Chat model:\\n{second_response['choices'][0]['message']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
